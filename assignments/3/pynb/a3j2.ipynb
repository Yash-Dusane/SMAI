{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
      "count    1143.000000       1143.000000  1143.000000     1143.000000   \n",
      "mean        8.311111          0.531339     0.268364        2.532152   \n",
      "std         1.747595          0.179633     0.196686        1.355917   \n",
      "min         4.600000          0.120000     0.000000        0.900000   \n",
      "25%         7.100000          0.392500     0.090000        1.900000   \n",
      "50%         7.900000          0.520000     0.250000        2.200000   \n",
      "75%         9.100000          0.640000     0.420000        2.600000   \n",
      "max        15.900000          1.580000     1.000000       15.500000   \n",
      "\n",
      "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
      "count  1143.000000          1143.000000           1143.000000  1143.000000   \n",
      "mean      0.086933            15.615486             45.914698     0.996730   \n",
      "std       0.047267            10.250486             32.782130     0.001925   \n",
      "min       0.012000             1.000000              6.000000     0.990070   \n",
      "25%       0.070000             7.000000             21.000000     0.995570   \n",
      "50%       0.079000            13.000000             37.000000     0.996680   \n",
      "75%       0.090000            21.000000             61.000000     0.997845   \n",
      "max       0.611000            68.000000            289.000000     1.003690   \n",
      "\n",
      "                pH    sulphates      alcohol      quality           Id  \n",
      "count  1143.000000  1143.000000  1143.000000  1143.000000  1143.000000  \n",
      "mean      3.311015     0.657708    10.442111     5.657043   804.969379  \n",
      "std       0.156664     0.170399     1.082196     0.805824   463.997116  \n",
      "min       2.740000     0.330000     8.400000     3.000000     0.000000  \n",
      "25%       3.205000     0.550000     9.500000     5.000000   411.000000  \n",
      "50%       3.310000     0.620000    10.200000     6.000000   794.000000  \n",
      "75%       3.400000     0.730000    11.100000     6.000000  1209.500000  \n",
      "max       4.010000     2.000000    14.900000     8.000000  1597.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('../../data/external/WineQT.csv')\n",
    "\n",
    "# Describe the dataset\n",
    "description = data.describe()\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the distribution of wine quality\n",
    "plt.figure(figsize=(10, 6))\n",
    "data['quality'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Distribution of Wine Quality')\n",
    "plt.xlabel('Quality')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.52157961  0.93933222 -1.36502663 ... -0.57365783 -0.96338181\n",
      "  -1.73561799]\n",
      " [-0.29259344  1.94181282 -1.36502663 ...  0.1308811  -0.59360107\n",
      "  -1.73346186]\n",
      " [-0.29259344  1.27349242 -1.16156762 ... -0.04525363 -0.59360107\n",
      "  -1.73130573]\n",
      " ...\n",
      " [-1.20853813  0.38239855 -0.9581086  ... -0.45623467  0.05351522\n",
      "   1.70125196]\n",
      " [-1.38027776  0.10393172 -0.8563791  ...  0.60057372  0.70063152\n",
      "   1.70340809]\n",
      " [-1.38027776  0.6330187  -0.75464959 ...  0.30701583 -0.22382033\n",
      "   1.70772035]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('quality', axis=1).values\n",
    "y = data['quality'].values\n",
    "\n",
    "# Normalize and standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(X_scaled)\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 524\n",
      "Accuracy: 64.04%\n",
      "Average relative error: 2.9110100995612392e-08\n",
      "Gradient check passed: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, \n",
    "                 hidden_layers, \n",
    "                 learning_rate=0.01,\n",
    "                 activation='sigmoid',\n",
    "                 optimizer='sgd',\n",
    "                 batch_size=32,\n",
    "                 epochs=100,\n",
    "                 early_stopping_patience=10):\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation = activation\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.losses = [] \n",
    "\n",
    "    def _initialize_parameters(self, input_size, output_size):\n",
    "        layer_sizes = [input_size] + self.hidden_layers + [output_size]\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.weights.append(np.random.randn(layer_sizes[i-1], layer_sizes[i]) * 0.01)\n",
    "            self.biases.append(np.zeros((1, layer_sizes[i])))\n",
    "\n",
    "    def _activation_function(self, x):\n",
    "        if self.activation == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-np.clip(x, -709, 709)))\n",
    "        elif self.activation == 'tanh':\n",
    "            return np.tanh(x)\n",
    "        elif self.activation == 'relu':\n",
    "            return np.maximum(0, x)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid activation function\")\n",
    "\n",
    "    def _activation_derivative(self, x):\n",
    "        if self.activation == 'sigmoid':\n",
    "            return x * (1 - x)\n",
    "        elif self.activation == 'tanh':\n",
    "            return 1 - np.power(x, 2)\n",
    "        elif self.activation == 'relu':\n",
    "            return np.where(x > 0, 1, 0)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid activation function\")\n",
    "\n",
    "    def _forward_propagation(self, X):\n",
    "        activations = [X]\n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
    "            a = self._activation_function(z)\n",
    "            activations.append(a)\n",
    "        return activations\n",
    "\n",
    "    def _backpropagation(self, X, y):\n",
    "        m = X.shape[0]\n",
    "        activations = self._forward_propagation(X)\n",
    "        \n",
    "        dW = [np.zeros_like(w) for w in self.weights]\n",
    "        db = [np.zeros_like(b) for b in self.biases]\n",
    "        \n",
    "        delta = activations[-1] - y\n",
    "        for l in range(len(self.weights) - 1, -1, -1):\n",
    "            dW[l] = np.dot(activations[l].T, delta) / m\n",
    "            db[l] = np.sum(delta, axis=0, keepdims=True) / m\n",
    "            if l > 0:\n",
    "                delta = np.dot(delta, self.weights[l].T) * self._activation_derivative(activations[l])\n",
    "        \n",
    "        return dW, db\n",
    "\n",
    "    def _update_parameters(self, dW, db):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * dW[i]\n",
    "            self.biases[i] -= self.learning_rate * db[i]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Adjust output values to be between 0 and 5 (for one-hot encoding)\n",
    "        y_adjusted = y - 3\n",
    "        \n",
    "        # Initialize parameters\n",
    "        n_classes = 6\n",
    "        self._initialize_parameters(n_features, n_classes)\n",
    "        \n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            if self.optimizer == 'sgd':\n",
    "                indices = np.random.permutation(n_samples)\n",
    "                X_shuffled = X[indices]\n",
    "                y_shuffled = y_adjusted[indices]\n",
    "                for i in range(n_samples):\n",
    "                    dW, db = self._backpropagation(X_shuffled[i:i+1], np.eye(n_classes)[y_shuffled[i:i+1]])\n",
    "                    self._update_parameters(dW, db)\n",
    "\n",
    "            elif self.optimizer == 'batch':\n",
    "                dW, db = self._backpropagation(X, np.eye(n_classes)[y_adjusted])\n",
    "                self._update_parameters(dW, db)\n",
    "\n",
    "            elif self.optimizer == 'mini_batch':\n",
    "                for i in range(0, n_samples, self.batch_size):\n",
    "                    batch_X = X[i:i+self.batch_size]\n",
    "                    batch_y = y_adjusted[i:i+self.batch_size]\n",
    "                    dW, db = self._backpropagation(batch_X, np.eye(n_classes)[batch_y])\n",
    "                    self._update_parameters(dW, db)\n",
    "\n",
    "            # Compute and store the loss for this epoch\n",
    "            loss = self._compute_cost(X, np.eye(n_classes)[y_adjusted])\n",
    "            self.losses.append(loss)  # Store the loss\n",
    "            \n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= self.early_stopping_patience:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "\n",
    "    def predict(self, X):\n",
    "        activations = self._forward_propagation(X)\n",
    "        predicted_indices = np.argmax(activations[-1], axis=1)\n",
    "        \n",
    "        # Adjust back to original quality scores (3-8)\n",
    "        return predicted_indices + 3\n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        return np.mean(y_true == y_pred)\n",
    "\n",
    "    def _compute_cost(self, X, y):\n",
    "        activations = self._forward_propagation(X)\n",
    "        m = X.shape[0]\n",
    "        epsilon = 1e-15\n",
    "        cost = -np.sum(y * np.log(activations[-1] + epsilon) + (1 - y) * np.log(1 - activations[-1] + epsilon)) / m\n",
    "        return cost\n",
    "\n",
    "    def gradient_check(self, X, y, epsilon=1e-7):\n",
    "        y_adjusted = y - 3\n",
    "        y_encoded = np.eye(6)[y_adjusted]\n",
    "        \n",
    "        dW, db = self._backpropagation(X, y_encoded)\n",
    "        \n",
    "        params = self.weights + self.biases\n",
    "        grads = dW + db\n",
    "        \n",
    "        num_grads = []\n",
    "        for param in params:\n",
    "            num_grad = np.zeros_like(param)\n",
    "            it = np.nditer(param, flags=['multi_index'], op_flags=['readwrite'])\n",
    "            while not it.finished:\n",
    "                idx = it.multi_index\n",
    "                old_value = param[idx]\n",
    "                \n",
    "                param[idx] = old_value + epsilon\n",
    "                cost_plus = self._compute_cost(X, y_encoded)\n",
    "                \n",
    "                param[idx] = old_value - epsilon\n",
    "                cost_minus = self._compute_cost(X, y_encoded)\n",
    "                \n",
    "                num_grad[idx] = (cost_plus - cost_minus) / (2 * epsilon)\n",
    "                \n",
    "                param[idx] = old_value\n",
    "                it.iternext()\n",
    "            \n",
    "            num_grads.append(num_grad)\n",
    "        \n",
    "        total_error = 0\n",
    "        for grad, num_grad in zip(grads, num_grads):\n",
    "            numerator = np.linalg.norm(grad - num_grad)\n",
    "            denominator = np.linalg.norm(grad) + np.linalg.norm(num_grad)\n",
    "            total_error += numerator / (denominator + 1e-7)\n",
    "        \n",
    "        average_error = total_error / len(params)\n",
    "        print(f\"Average relative error: {average_error}\")\n",
    "        \n",
    "        return average_error < 1e-7\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Create an instance of the MLP class with specified parameters.\n",
    "    mlp=MLP(hidden_layers=[9],\n",
    "            learning_rate=0.01,\n",
    "            activation='sigmoid',\n",
    "            optimizer='sgd',batch_size=32,\n",
    "            epochs=1000)\n",
    "\n",
    "    # Fit the model on training data.\n",
    "    mlp.fit(X_train,y_train)\n",
    "\n",
    "    # Make predictions on the test set.\n",
    "    predictions=mlp.predict(X_val)\n",
    "\n",
    "   # Calculate accuracy.\n",
    "    accuracy_score=mlp.accuracy(y_val,predictions)\n",
    "    print(f\"Accuracy: {accuracy_score * 100:.2f}%\")\n",
    "\n",
    "    # Perform gradient checking on a sample of test data.\n",
    "    is_gradient_correct=mlp.gradient_check(X_val,y_val)\n",
    "    print(f\"Gradient check passed: {is_gradient_correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: dty5miyw\n",
      "Sweep URL: https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning/sweeps/dty5miyw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: htj2ilda with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 150\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [10, 8]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08087946999079179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_005513-htj2ilda</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning/runs/htj2ilda' target=\"_blank\">wild-sweep-1</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning/sweeps/dty5miyw' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning/sweeps/dty5miyw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning/sweeps/dty5miyw' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning/sweeps/dty5miyw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning/runs/htj2ilda' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning/runs/htj2ilda</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_4724\\1362981141.py:155: RuntimeWarning: invalid value encountered in log\n",
      "  cost = -np.sum(y * np.log(activations[-1] + epsilon) + (1 - y) * np.log(1 - activations[-1] + epsilon)) / m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_accuracy</td><td>▁▇█▄█</td></tr><tr><td>val_accuracy</td><td>▁▅█▆▇▇</td></tr><tr><td>val_f1</td><td>▁</td></tr><tr><td>val_precision</td><td>▁</td></tr><tr><td>val_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_accuracy</td><td>0.5919</td></tr><tr><td>train_loss</td><td>nan</td></tr><tr><td>val_accuracy</td><td>0.61404</td></tr><tr><td>val_f1</td><td>0.57494</td></tr><tr><td>val_loss</td><td>nan</td></tr><tr><td>val_precision</td><td>0.54445</td></tr><tr><td>val_recall</td><td>0.61404</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wild-sweep-1</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning/runs/htj2ilda' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning/runs/htj2ilda</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP_Hyperparameter_Tuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_005513-htj2ilda\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "ename": "CommError",
     "evalue": "Could not find sweep <Sweep your_username/MLP_Hyperparameter_Tuning/dty5miyw (Unknown State)>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\apis\\normalize.py:41\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\apis\\public\\api.py:1030\u001b[0m, in \u001b[0;36mApi.sweep\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sweeps\u001b[38;5;241m.\u001b[39mget(path):\n\u001b[1;32m-> 1030\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sweeps[path] \u001b[38;5;241m=\u001b[39m \u001b[43mpublic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSweep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msweep_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sweeps[path]\n",
      "File \u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\apis\\public\\sweeps.py:91\u001b[0m, in \u001b[0;36mSweep.__init__\u001b[1;34m(self, client, entity, project, sweep_id, attrs)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruns \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\apis\\public\\sweeps.py:110\u001b[0m, in \u001b[0;36mSweep.load\u001b[1;34m(self, force)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sweep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find sweep \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;241m=\u001b[39m sweep\u001b[38;5;241m.\u001b[39m_attrs\n",
      "\u001b[1;31mValueError\u001b[0m: Could not find sweep <Sweep your_username/MLP_Hyperparameter_Tuning/dty5miyw (Unknown State)>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 244\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# After the sweep is complete, you can get the best run:\u001b[39;00m\n\u001b[0;32m    243\u001b[0m api \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mApi()\n\u001b[1;32m--> 244\u001b[0m sweep \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msweep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myour_username/MLP_Hyperparameter_Tuning/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msweep_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m best_run \u001b[38;5;241m=\u001b[39m sweep\u001b[38;5;241m.\u001b[39mbest_run()\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest run id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_run\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\apis\\normalize.py:87\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CommError(message, err)\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\apis\\normalize.py:41\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhoa, you found a bug.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m     43\u001b[0m     errors \u001b[38;5;241m=\u001b[39m parse_backend_error_messages(error\u001b[38;5;241m.\u001b[39mresponse)\n",
      "File \u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\apis\\public\\api.py:1030\u001b[0m, in \u001b[0;36mApi.sweep\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1028\u001b[0m entity, project, sweep_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_path(path)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sweeps\u001b[38;5;241m.\u001b[39mget(path):\n\u001b[1;32m-> 1030\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sweeps[path] \u001b[38;5;241m=\u001b[39m \u001b[43mpublic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSweep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msweep_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sweeps[path]\n",
      "File \u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\apis\\public\\sweeps.py:91\u001b[0m, in \u001b[0;36mSweep.__init__\u001b[1;34m(self, client, entity, project, sweep_id, attrs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m sweep_id\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruns \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\apis\\public\\sweeps.py:110\u001b[0m, in \u001b[0;36mSweep.load\u001b[1;34m(self, force)\u001b[0m\n\u001b[0;32m    108\u001b[0m sweep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentity, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sweep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find sweep \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;241m=\u001b[39m sweep\u001b[38;5;241m.\u001b[39m_attrs\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruns \u001b[38;5;241m=\u001b[39m sweep\u001b[38;5;241m.\u001b[39mruns\n",
      "\u001b[1;31mCommError\u001b[0m: Could not find sweep <Sweep your_username/MLP_Hyperparameter_Tuning/dty5miyw (Unknown State)>"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "class MLP_hyperparam:\n",
    "    def __init__(self, config):\n",
    "        self.hidden_layers = config.hidden_layers\n",
    "        self.learning_rate = config.learning_rate\n",
    "        self.activation = config.activation\n",
    "        self.optimizer = config.optimizer\n",
    "        self.batch_size = config.batch_size\n",
    "        self.epochs = config.epochs\n",
    "        self.early_stopping_patience = config.early_stopping_patience\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "    def _initialize_parameters(self, input_size, output_size):\n",
    "        layer_sizes = [input_size] + self.hidden_layers + [output_size]\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.weights.append(np.random.randn(layer_sizes[i-1], layer_sizes[i]) * 0.01)\n",
    "            self.biases.append(np.zeros((1, layer_sizes[i])))\n",
    "\n",
    "    def _activation_function(self, x):\n",
    "        if self.activation == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        elif self.activation == 'tanh':\n",
    "            return np.tanh(x)\n",
    "        elif self.activation == 'relu':\n",
    "            return np.maximum(0, x)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid activation function\")\n",
    "\n",
    "    def _activation_derivative(self, x):\n",
    "        if self.activation == 'sigmoid':\n",
    "            return x * (1 - x)\n",
    "        elif self.activation == 'tanh':\n",
    "            return 1 - np.power(x, 2)\n",
    "        elif self.activation == 'relu':\n",
    "            return np.where(x > 0, 1, 0)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid activation function\")\n",
    "\n",
    "    def _forward_propagation(self, X):\n",
    "        activations = [X]\n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
    "            a = self._activation_function(z)\n",
    "            activations.append(a)\n",
    "        return activations\n",
    "\n",
    "    def _backpropagation(self, X, y):\n",
    "        m = X.shape[0]\n",
    "        activations = self._forward_propagation(X)\n",
    "        \n",
    "        dW = [np.zeros_like(w) for w in self.weights]\n",
    "        db = [np.zeros_like(b) for b in self.biases]\n",
    "        \n",
    "        delta = activations[-1] - y\n",
    "        for l in range(len(self.weights) - 1, -1, -1):\n",
    "            dW[l] = np.dot(activations[l].T, delta) / m\n",
    "            db[l] = np.sum(delta, axis=0, keepdims=True) / m\n",
    "            if l > 0:\n",
    "                delta = np.dot(delta, self.weights[l].T) * self._activation_derivative(activations[l])\n",
    "        \n",
    "        return dW, db\n",
    "\n",
    "    def _update_parameters(self, dW, db):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * dW[i]\n",
    "            self.biases[i] -= self.learning_rate * db[i]\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        \n",
    "        n_samples, n_features = X_train.shape\n",
    "        \n",
    "        # Adjust output values to be between 0 and 5 (for one-hot encoding)\n",
    "        y_train_adjusted = y_train - 3  # Shift labels from [3-8] to [0-5]\n",
    "        y_val_adjusted = y_val - 3\n",
    "        \n",
    "        # Initialize parameters\n",
    "        n_classes = 6  # Since we have classes from 0 to 5 after adjustment\n",
    "        self._initialize_parameters(n_features, n_classes)\n",
    "        \n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            if self.optimizer == 'sgd':\n",
    "                indices = np.random.permutation(n_samples)\n",
    "                X_shuffled = X_train[indices]\n",
    "                y_shuffled = y_train_adjusted[indices]\n",
    "                for i in range(n_samples):\n",
    "                    dW, db = self._backpropagation(X_shuffled[i:i+1], np.eye(n_classes)[y_shuffled[i:i+1]])\n",
    "                    self._update_parameters(dW, db)\n",
    "            elif self.optimizer == 'batch':\n",
    "                dW, db = self._backpropagation(X_train, np.eye(n_classes)[y_train_adjusted])\n",
    "                self._update_parameters(dW, db)\n",
    "            elif self.optimizer == 'mini_batch':\n",
    "                for i in range(0, n_samples, self.batch_size):\n",
    "                    batch_X = X_train[i:i+self.batch_size]\n",
    "                    batch_y = y_train_adjusted[i:i+self.batch_size]\n",
    "                    dW, db = self._backpropagation(batch_X, np.eye(n_classes)[batch_y])\n",
    "                    self._update_parameters(dW, db)\n",
    "\n",
    "            train_loss = self._compute_cost(X_train, np.eye(n_classes)[y_train_adjusted])\n",
    "            val_loss = self._compute_cost(X_val, np.eye(n_classes)[y_val_adjusted])\n",
    "            \n",
    "            train_pred = self.predict(X_train)\n",
    "            val_pred = self.predict(X_val)\n",
    "            train_accuracy = self.accuracy(y_train, train_pred)\n",
    "            val_accuracy = self.accuracy(y_val, val_pred)\n",
    "            \n",
    "            wandb.log({\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"val_accuracy\": val_accuracy\n",
    "            })\n",
    "            \n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= self.early_stopping_patience:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "\n",
    "        # Compute final metrics\n",
    "        final_pred = self.predict(X_val)\n",
    "        final_metrics = {\n",
    "            \"val_accuracy\": accuracy_score(y_val, final_pred),\n",
    "            \"val_f1\": f1_score(y_val, final_pred, average='weighted'),\n",
    "            \"val_precision\": precision_score(y_val, final_pred, average='weighted'),\n",
    "            \"val_recall\": recall_score(y_val, final_pred, average='weighted')\n",
    "        }\n",
    "        wandb.log(final_metrics)\n",
    "\n",
    "    def predict(self, X):\n",
    "        activations = self._forward_propagation(X)\n",
    "        predicted_indices = np.argmax(activations[-1], axis=1)\n",
    "        \n",
    "        # Adjust back to original quality scores (3-8)\n",
    "        return predicted_indices + 3\n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        return np.mean(y_true == y_pred)\n",
    "\n",
    "    def _compute_cost(self, X, y):\n",
    "        activations = self._forward_propagation(X)\n",
    "        m = X.shape[0]\n",
    "        epsilon = 1e-15\n",
    "        cost = -np.sum(y * np.log(activations[-1] + epsilon) + (1 - y) * np.log(1 - activations[-1] + epsilon)) / m\n",
    "        return cost\n",
    "\n",
    "    def gradient_check(self, X, y, epsilon=1e-7):\n",
    "        y_adjusted = y - 3\n",
    "        y_encoded = np.eye(6)[y_adjusted]\n",
    "        \n",
    "        dW, db = self._backpropagation(X, y_encoded)\n",
    "        \n",
    "        params = self.weights + self.biases\n",
    "        grads = dW + db\n",
    "        \n",
    "        num_grads = []\n",
    "        for param in params:\n",
    "            num_grad = np.zeros_like(param)\n",
    "            it = np.nditer(param, flags=['multi_index'], op_flags=['readwrite'])\n",
    "            while not it.finished:\n",
    "                idx = it.multi_index\n",
    "                old_value = param[idx]\n",
    "                \n",
    "                param[idx] = old_value + epsilon\n",
    "                cost_plus = self._compute_cost(X, y_encoded)\n",
    "                \n",
    "                param[idx] = old_value - epsilon\n",
    "                cost_minus = self._compute_cost(X, y_encoded)\n",
    "                \n",
    "                num_grad[idx] = (cost_plus - cost_minus) / (2 * epsilon)\n",
    "                \n",
    "                param[idx] = old_value\n",
    "                it.iternext()\n",
    "            \n",
    "            num_grads.append(num_grad)\n",
    "        \n",
    "        total_error = 0\n",
    "        for grad, num_grad in zip(grads, num_grads):\n",
    "            numerator = np.linalg.norm(grad - num_grad)\n",
    "            denominator = np.linalg.norm(grad) + np.linalg.norm(num_grad)\n",
    "            total_error += numerator / (denominator + 1e-7)\n",
    "        \n",
    "        average_error = total_error / len(params)\n",
    "        print(f\"Average relative error: {average_error}\")\n",
    "        \n",
    "        return average_error < 1e-7\n",
    "    \n",
    "def train():\n",
    "    # Load your data here\n",
    "    # X, y = load_data()  # Implement this function to load your dataset\n",
    "    \n",
    "    # For demonstration, let's create some dummy data\n",
    "    # X = np.random.randn(1000, 10)\n",
    "    # y = np.random.randint(3, 9, size=1000)\n",
    "\n",
    "    config_defaults = {\n",
    "        'hidden_layers': [64],\n",
    "        'learning_rate': 0.01,\n",
    "        'activation': 'sigmoid',\n",
    "        'optimizer': 'sgd',\n",
    "        'batch_size': 32,\n",
    "        'epochs': 100,\n",
    "        'early_stopping_patience': 10\n",
    "    }\n",
    "\n",
    "    wandb.init(config=config_defaults)\n",
    "    config = wandb.config\n",
    "\n",
    "    model = MLP_hyperparam(config)\n",
    "    model.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "sweep_configuration = {\n",
    "    'method': 'random',\n",
    "    'name': 'sweep',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_accuracy'},\n",
    "    'parameters': \n",
    "    {\n",
    "        'hidden_layers': {'values': [[9], [10, 8], [64, 32]]},\n",
    "        'learning_rate': {'min': 0.0001, 'max': 0.1},\n",
    "        'activation': {'values': ['sigmoid', 'relu', 'tanh']},\n",
    "        'optimizer': {'values': ['sgd', 'batch', 'mini_batch']},\n",
    "        'batch_size': {'values': [16, 32, 64]},\n",
    "        'epochs': {'values': [50, 100, 150]},\n",
    "        'early_stopping_patience': {'values': [5, 10, 15]}\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_configuration, project=\"MLP_Hyperparameter_Tuning\")\n",
    "wandb.agent(sweep_id, train, count=20)  # Run 20 experiments\n",
    "\n",
    "# After the sweep is complete, you can get the best run:\n",
    "api = wandb.Api()\n",
    "sweep = api.sweep(f\"your_username/MLP_Hyperparameter_Tuning/{sweep_id}\")\n",
    "best_run = sweep.best_run()\n",
    "print(f\"Best run id: {best_run.id}\")\n",
    "print(f\"Best run config: {best_run.config}\")\n",
    "print(f\"Best run metrics: {best_run.summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdusaneyash09\u001b[0m (\u001b[33mdusaneyash09-iiit-hyderabad\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241010_183611-2r3odja0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-hyperparameter-tuning/runs/2r3odja0' target=\"_blank\">grateful-tree-5</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-hyperparameter-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-hyperparameter-tuning' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-hyperparameter-tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-hyperparameter-tuning/runs/2r3odja0' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-hyperparameter-tuning/runs/2r3odja0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 32\n",
      "Accuracy: 63.76%\n",
      "Precision: 0.61, Recall: 0.64, F1 Score: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import wandb\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# class MLP:\n",
    "#     def __init__(self, \n",
    "#                  hidden_layers, \n",
    "#                  learning_rate=0.01,\n",
    "#                  activation='sigmoid',\n",
    "#                  optimizer='sgd',\n",
    "#                  batch_size=32,\n",
    "#                  epochs=100,\n",
    "#                  early_stopping_patience=10):\n",
    "#         self.hidden_layers = hidden_layers\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.activation = activation\n",
    "#         self.optimizer = optimizer\n",
    "#         self.batch_size = batch_size\n",
    "#         self.epochs = epochs\n",
    "#         self.early_stopping_patience = early_stopping_patience\n",
    "#         self.weights = []\n",
    "#         self.biases = []\n",
    "\n",
    "#     def _initialize_parameters(self, input_size, output_size):\n",
    "#         layer_sizes = [input_size] + self.hidden_layers + [output_size]\n",
    "#         for i in range(1, len(layer_sizes)):\n",
    "#             self.weights.append(np.random.randn(layer_sizes[i-1], layer_sizes[i]) / np.sqrt(layer_sizes[i-1]))\n",
    "#             self.biases.append(np.zeros((1, layer_sizes[i])))\n",
    "\n",
    "#     def _activation_function(self, x):\n",
    "#         if self.activation == 'sigmoid':\n",
    "#             return 1 / (1 + np.exp(-np.clip(x, -709, 709)))  # Clip to avoid overflow\n",
    "#         elif self.activation == 'tanh':\n",
    "#             return np.tanh(x)\n",
    "#         elif self.activation == 'relu':\n",
    "#             return np.maximum(0, x)\n",
    "#         elif self.activation == 'linear':\n",
    "#             return x\n",
    "#         else:\n",
    "#             raise ValueError(\"Invalid activation function\")\n",
    "\n",
    "#     def _activation_derivative(self, x):\n",
    "#         if self.activation == 'sigmoid':\n",
    "#             return x * (1 - x)\n",
    "#         elif self.activation == 'tanh':\n",
    "#             return 1 - np.power(x, 2)\n",
    "#         elif self.activation == 'relu':\n",
    "#             return np.where(x > 0, 1, 0)\n",
    "#         elif self.activation == 'linear':\n",
    "#             return np.ones_like(x)\n",
    "#         else:\n",
    "#             raise ValueError(\"Invalid activation function\")\n",
    "\n",
    "#     def _forward_propagation(self, X):\n",
    "#         activations = [X]\n",
    "#         for i in range(len(self.weights)):\n",
    "#             z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
    "#             a = self._activation_function(z)\n",
    "#             activations.append(a)\n",
    "#         return activations\n",
    "\n",
    "#     def _backpropagation(self, X, y):\n",
    "#         m = X.shape[0]\n",
    "#         activations = self._forward_propagation(X)\n",
    "        \n",
    "#         dW = [np.zeros_like(w) for w in self.weights]\n",
    "#         db = [np.zeros_like(b) for b in self.biases]\n",
    "        \n",
    "#         delta = activations[-1] - y\n",
    "#         for l in range(len(self.weights) - 1, -1, -1):\n",
    "#             dW[l] = np.dot(activations[l].T, delta) / m\n",
    "#             db[l] = np.sum(delta, axis=0, keepdims=True) / m\n",
    "#             if l > 0:\n",
    "#                 delta = np.dot(delta, self.weights[l].T) * self._activation_derivative(activations[l])\n",
    "        \n",
    "#         return dW, db\n",
    "\n",
    "#     def _update_parameters(self, dW, db):\n",
    "#         for i in range(len(self.weights)):\n",
    "#             self.weights[i] -= self.learning_rate * dW[i]\n",
    "#             self.biases[i] -= self.learning_rate * db[i]\n",
    "\n",
    "#     def fit(self, X_train, y_train, X_val=None, y_val=None):\n",
    "        \n",
    "#         n_samples, n_features = X_train.shape\n",
    "        \n",
    "#         # Adjust output values to be between 0 and 5 (for one-hot encoding)\n",
    "#         y_adjusted_train = y_train - 3\n",
    "        \n",
    "#         # Initialize parameters\n",
    "#         n_classes = 6  \n",
    "#         self._initialize_parameters(n_features, n_classes)\n",
    "        \n",
    "#         best_loss = float('inf')\n",
    "#         patience_counter = 0\n",
    "        \n",
    "#         # Initialize W&B logging\n",
    "#         wandb.init(project=\"mlp-hyperparameter-tuning\", config={\n",
    "#             \"learning_rate\": self.learning_rate,\n",
    "#             \"epochs\": self.epochs,\n",
    "#             \"batch_size\": self.batch_size,\n",
    "#             \"hidden_layers\": str(self.hidden_layers),\n",
    "#             \"activation\": self.activation,\n",
    "#             \"optimizer\": self.optimizer\n",
    "#         })\n",
    "        \n",
    "#         for epoch in range(self.epochs):\n",
    "#             # Training phase\n",
    "#             if self.optimizer == 'sgd':\n",
    "#                 indices = np.random.permutation(n_samples)\n",
    "#                 X_shuffled = X_train[indices]\n",
    "#                 y_encoded_shuffled = y_adjusted_train[indices]\n",
    "#                 for i in range(n_samples):\n",
    "#                     dW, db = self._backpropagation(X_shuffled[i:i+1], np.eye(n_classes)[y_encoded_shuffled[i:i+1]])\n",
    "#                     self._update_parameters(dW, db)\n",
    "\n",
    "#             elif self.optimizer == 'batch':\n",
    "#                 dW, db = self._backpropagation(X_train, np.eye(n_classes)[y_adjusted_train])\n",
    "#                 self._update_parameters(dW, db)\n",
    "\n",
    "#             elif self.optimizer == 'mini_batch':\n",
    "#                 for i in range(0, n_samples, self.batch_size):\n",
    "#                     batch_X = X_train[i:i+self.batch_size]\n",
    "#                     batch_y = y_adjusted_train[i:i+self.batch_size]\n",
    "#                     dW, db = self._backpropagation(batch_X, np.eye(n_classes)[batch_y])\n",
    "#                     self._update_parameters(dW, db)\n",
    "\n",
    "#             train_loss = self._compute_cost(X_train, np.eye(n_classes)[y_adjusted_train])\n",
    "            \n",
    "#             # Log metrics to W&B\n",
    "#             wandb.log({\"epoch\": epoch + 1,\n",
    "#                         \"train_loss\": train_loss})\n",
    "\n",
    "#             if X_val is not None and y_val is not None:\n",
    "#                 val_loss = self._compute_cost(X_val, np.eye(n_classes)[y_val - 3])\n",
    "#                 val_accuracy = self.accuracy(y_val, self.predict(X_val))\n",
    "                \n",
    "#                 # Log validation metrics to W&B\n",
    "#                 wandb.log({\"val_loss\": val_loss,\n",
    "#                             \"val_accuracy\": val_accuracy})\n",
    "\n",
    "#                 if val_loss < best_loss:\n",
    "#                     best_loss = val_loss\n",
    "#                     patience_counter = 0\n",
    "#                 else:\n",
    "#                     patience_counter += 1\n",
    "#                     if patience_counter >= self.early_stopping_patience:\n",
    "#                         print(f\"Early stopping at epoch {epoch}\")\n",
    "#                         break\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         activations = self._forward_propagation(X)\n",
    "#         predicted_indices = np.argmax(activations[-1], axis=1)\n",
    "        \n",
    "#         # Adjust back to original quality scores (3-8)\n",
    "#         return predicted_indices + 3\n",
    "\n",
    "#     def accuracy(self, y_true, y_pred):\n",
    "#         return np.mean(y_true == y_pred)\n",
    "\n",
    "#     def _compute_cost(self, X, y):\n",
    "#        activations=self._forward_propagation(X)\n",
    "#        m=X.shape[0]\n",
    "#        epsilon=1e-15 # To avoid log(0).\n",
    "#        cost=-np.sum(y*np.log(activations[-1]+epsilon))/m\n",
    "      \n",
    "#        return cost\n",
    "\n",
    "# # Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "   \n",
    "#        # Create an instance of the MLP class with specified parameters.\n",
    "#     mlp=MLP(hidden_layers=[10],learning_rate=0.01,batch_size=32,\n",
    "#                 epochs=1000)\n",
    "\n",
    "#     # Fit the model on training data and validate on test data.\n",
    "#     mlp.fit(X_train,y_train,X_test,y_test)\n",
    "\n",
    "#     # Make predictions on the test set.\n",
    "#     predictions=mlp.predict(X_test)\n",
    "\n",
    "#     # Calculate accuracy.\n",
    "#     accuracy_score=mlp.accuracy(y_test,predictions)\n",
    "#     print(f\"Accuracy: {accuracy_score * 100:.2f}%\")\n",
    "\n",
    "#     # Calculate additional metrics.\n",
    "#     precision = precision_score(y_test, predictions, average='weighted')\n",
    "#     recall = recall_score(y_test, predictions, average='weighted')\n",
    "#     f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "#     print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2r3odja0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▇▅▅▃▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▃▁▂▂▁▁▂▁▂▂▂▂</td></tr><tr><td>val_accuracy</td><td>▁▃▄▃▄▃▆▆▅▆▄▆▇▆▆▆▆▇▅▆▆█▆▆▇▆▆▇▅▆▆█▆</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▃▂▂▂▃▂▃▃▂▃▂▂▂▁▂▂▃▁▂▂▂▂▂▁▃▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>33</td></tr><tr><td>train_loss</td><td>0.91586</td></tr><tr><td>val_accuracy</td><td>0.63755</td></tr><tr><td>val_loss</td><td>0.87694</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">grateful-tree-5</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-hyperparameter-tuning/runs/2r3odja0' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-hyperparameter-tuning/runs/2r3odja0</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-hyperparameter-tuning' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-hyperparameter-tuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241010_183611-2r3odja0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2r3odja0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241010_184347-2vlew3sf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality/runs/2vlew3sf' target=\"_blank\">flowing-flower-1</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality/runs/2vlew3sf' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality/runs/2vlew3sf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2vlew3sf) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">flowing-flower-1</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality/runs/2vlew3sf' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality/runs/2vlew3sf</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241010_184347-2vlew3sf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2vlew3sf). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241010_184352-cbv4v2u7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality/runs/cbv4v2u7' target=\"_blank\">cosmic-wood-2</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality/runs/cbv4v2u7' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/mlp-wine-quality/runs/cbv4v2u7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "<class 'wandb.sdk.wandb_config.Config'> object has no attribute 'hidden_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\sdk\\wandb_config.py:165\u001b[0m, in \u001b[0;36mConfig.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ke:\n",
      "File \u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\sdk\\wandb_config.py:130\u001b[0m, in \u001b[0;36mConfig.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hidden_layers'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 259\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Main execution\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Load your data here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;66;03m# X, y = load_wine_quality_data()\u001b[39;00m\n\u001b[0;32m    257\u001b[0m     \n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# Run hyperparameter search\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m     best_model, results \u001b[38;5;241m=\u001b[39m \u001b[43mhyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# Print results table\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mHyperparameter Search Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 234\u001b[0m, in \u001b[0;36mhyperparameter_search\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# Initialize W&B\u001b[39;00m\n\u001b[0;32m    233\u001b[0m run \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp-wine-quality\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m--> 234\u001b[0m model, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m run\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m    237\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m: hidden_layers,\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: learning_rate,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy\n\u001b[0;32m    245\u001b[0m })\n",
      "Cell \u001b[1;32mIn[10], line 172\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(config, X, y)\u001b[0m\n\u001b[0;32m    168\u001b[0m config \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mconfig  \u001b[38;5;66;03m# This will be a namespace object\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# Create and train the model\u001b[39;00m\n\u001b[0;32m    171\u001b[0m mlp \u001b[38;5;241m=\u001b[39m MLPClassifier(\n\u001b[1;32m--> 172\u001b[0m     hidden_layers\u001b[38;5;241m=\u001b[39m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_layers\u001b[49m,\n\u001b[0;32m    173\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlearning_rate,\n\u001b[0;32m    174\u001b[0m     activation\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mactivation,\n\u001b[0;32m    175\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39moptimizer,\n\u001b[0;32m    176\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m    177\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mepochs\n\u001b[0;32m    178\u001b[0m )\n\u001b[0;32m    180\u001b[0m mlp\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, X_val, y_val)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\sdk\\wandb_config.py:167\u001b[0m, in \u001b[0;36mConfig.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(key)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ke:\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    169\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mke\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: <class 'wandb.sdk.wandb_config.Config'> object has no attribute 'hidden_layers'"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import wandb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# class MLPClassifier:\n",
    "#     def __init__(self, \n",
    "#                  hidden_layers, \n",
    "#                  learning_rate=0.01,\n",
    "#                  activation='sigmoid',\n",
    "#                  optimizer='sgd',\n",
    "#                  batch_size=32,\n",
    "#                  epochs=100,\n",
    "#                  early_stopping_patience=10):\n",
    "#         self.hidden_layers = hidden_layers\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.activation = activation\n",
    "#         self.optimizer = optimizer\n",
    "#         self.batch_size = batch_size\n",
    "#         self.epochs = epochs\n",
    "#         self.early_stopping_patience = early_stopping_patience\n",
    "#         self.weights = []\n",
    "#         self.biases = []\n",
    "#         self.class_mapping = {}\n",
    "#         self.inverse_class_mapping = {}\n",
    "\n",
    "#     def _initialize_parameters(self, input_size, output_size):\n",
    "#         layer_sizes = [input_size] + self.hidden_layers + [output_size]\n",
    "#         for i in range(1, len(layer_sizes)):\n",
    "#             self.weights.append(np.random.randn(layer_sizes[i-1], layer_sizes[i]) / np.sqrt(layer_sizes[i-1]))\n",
    "#             self.biases.append(np.zeros((1, layer_sizes[i])))\n",
    "\n",
    "#     def _activation_function(self, x):\n",
    "#         activations = {\n",
    "#             'sigmoid': lambda x: 1 / (1 + np.exp(-x)),\n",
    "#             'tanh': np.tanh,\n",
    "#             'relu': lambda x: np.maximum(0, x),\n",
    "#             'linear': lambda x: x\n",
    "#         }\n",
    "#         return activations[self.activation](x)\n",
    "\n",
    "#     def _activation_derivative(self, x):\n",
    "#         derivatives = {\n",
    "#             'sigmoid': lambda x: x * (1 - x),\n",
    "#             'tanh': lambda x: 1 - np.power(x, 2),\n",
    "#             'relu': lambda x: np.where(x > 0, 1, 0),\n",
    "#             'linear': lambda x: np.ones_like(x)\n",
    "#         }\n",
    "#         return derivatives[self.activation](x)\n",
    "\n",
    "#     def _forward_propagation(self, X):\n",
    "#         activations = [X]\n",
    "#         for i in range(len(self.weights)):\n",
    "#             z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
    "#             a = self._activation_function(z)\n",
    "#             activations.append(a)\n",
    "#         return activations\n",
    "\n",
    "#     def _backpropagation(self, X, y):\n",
    "#         m = X.shape[0]\n",
    "#         activations = self._forward_propagation(X)\n",
    "        \n",
    "#         dW = [np.zeros_like(w) for w in self.weights]\n",
    "#         db = [np.zeros_like(b) for b in self.biases]\n",
    "        \n",
    "#         delta = activations[-1] - y\n",
    "#         for l in range(len(self.weights) - 1, -1, -1):\n",
    "#             dW[l] = np.dot(activations[l].T, delta) / m\n",
    "#             db[l] = np.sum(delta, axis=0, keepdims=True) / m\n",
    "#             if l > 0:\n",
    "#                 delta = np.dot(delta, self.weights[l].T) * self._activation_derivative(activations[l])\n",
    "        \n",
    "#         return dW, db\n",
    "\n",
    "#     def _update_parameters(self, dW, db):\n",
    "#         for i in range(len(self.weights)):\n",
    "#             self.weights[i] -= self.learning_rate * dW[i]\n",
    "#             self.biases[i] -= self.learning_rate * db[i]\n",
    "\n",
    "#     def fit(self, X, y, X_val, y_val):\n",
    "#         n_samples, n_features = X.shape\n",
    "        \n",
    "#         y_encoded = self._one_hot_encode(y)\n",
    "#         y_val_encoded = self._one_hot_encode(y_val)\n",
    "#         n_classes = y_encoded.shape[1]\n",
    "        \n",
    "#         self._initialize_parameters(n_features, n_classes)\n",
    "        \n",
    "#         best_loss = float('inf')\n",
    "#         patience_counter = 0\n",
    "        \n",
    "#         for epoch in range(self.epochs):\n",
    "#             if self.optimizer == 'sgd':\n",
    "#                 indices = np.random.permutation(n_samples)\n",
    "#                 X = X[indices]\n",
    "#                 y_encoded = y_encoded[indices]\n",
    "#                 for i in range(n_samples):\n",
    "#                     dW, db = self._backpropagation(X[i:i+1], y_encoded[i:i+1])\n",
    "#                     self._update_parameters(dW, db)\n",
    "#             elif self.optimizer == 'batch':\n",
    "#                 dW, db = self._backpropagation(X, y_encoded)\n",
    "#                 self._update_parameters(dW, db)\n",
    "#             elif self.optimizer == 'mini_batch':\n",
    "#                 for i in range(0, n_samples, self.batch_size):\n",
    "#                     batch_X = X[i:i+self.batch_size]\n",
    "#                     batch_y = y_encoded[i:i+self.batch_size]\n",
    "#                     dW, db = self._backpropagation(batch_X, batch_y)\n",
    "#                     self._update_parameters(dW, db)\n",
    "            \n",
    "#             train_loss = self._compute_cost(X, y_encoded)\n",
    "#             val_loss = self._compute_cost(X_val, y_val_encoded)\n",
    "            \n",
    "#             train_acc = self.accuracy(y, self.predict(X))\n",
    "#             val_acc = self.accuracy(y_val, self.predict(X_val))\n",
    "            \n",
    "#             wandb.log({\n",
    "#                 \"epoch\": epoch,\n",
    "#                 \"train_loss\": train_loss,\n",
    "#                 \"val_loss\": val_loss,\n",
    "#                 \"train_accuracy\": train_acc,\n",
    "#                 \"val_accuracy\": val_acc\n",
    "#             })\n",
    "            \n",
    "#             if val_loss < best_loss:\n",
    "#                 best_loss = val_loss\n",
    "#                 patience_counter = 0\n",
    "#             else:\n",
    "#                 patience_counter += 1\n",
    "#                 if patience_counter >= self.early_stopping_patience:\n",
    "#                     print(f\"Early stopping at epoch {epoch}\")\n",
    "#                     break\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         activations = self._forward_propagation(X)\n",
    "#         predicted_indices = np.argmax(activations[-1], axis=1)\n",
    "#         return predicted_indices + 3  # Adjust to original quality scores\n",
    "\n",
    "#     def accuracy(self, y_true, y_pred):\n",
    "#         return np.mean(y_true == y_pred)\n",
    "\n",
    "#     def _compute_cost(self, X, y):\n",
    "#         activations = self._forward_propagation(X)\n",
    "#         m = X.shape[0]\n",
    "#         epsilon = 1e-15  # To avoid log(0)\n",
    "#         cost = -np.sum(y * np.log(activations[-1] + epsilon)) / m\n",
    "#         return cost\n",
    "\n",
    "#     def evaluate(self, X, y):\n",
    "#         y_pred = self.predict(X)\n",
    "#         acc = accuracy_score(y, y_pred)\n",
    "#         f1 = f1_score(y, y_pred, average='weighted')\n",
    "#         precision = precision_score(y, y_pred, average='weighted')\n",
    "#         recall = recall_score(y, y_pred, average='weighted')\n",
    "#         return acc, f1, precision, recall\n",
    "\n",
    "#     def _one_hot_encode(self, y):\n",
    "#         n_classes = np.max(y) + 1\n",
    "#         return np.eye(n_classes)[y]\n",
    "\n",
    "# def run_experiment(config, X, y):\n",
    "#     # Split the data\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     # Initialize W&B with a configuration dictionary\n",
    "#     run = wandb.init(project=\"mlp-wine-quality\", config=config)\n",
    "    \n",
    "#     # Retrieve config from run\n",
    "#     config = wandb.config  # This will be a namespace object\n",
    "    \n",
    "#     # Create and train the model\n",
    "#     mlp = MLPClassifier(\n",
    "#         hidden_layers=config.hidden_layers,\n",
    "#         learning_rate=config.learning_rate,\n",
    "#         activation=config.activation,\n",
    "#         optimizer=config.optimizer,\n",
    "#         batch_size=config.batch_size,\n",
    "#         epochs=config.epochs\n",
    "#     )\n",
    "    \n",
    "#     mlp.fit(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "#     # Evaluate the model\n",
    "#     train_acc, train_f1, train_precision, train_recall = mlp.evaluate(X_train, y_train)\n",
    "#     val_acc, val_f1, val_precision, val_recall = mlp.evaluate(X_val, y_val)\n",
    "    \n",
    "#     # Log final metrics\n",
    "#     wandb.log({\n",
    "#         \"final_train_accuracy\": train_acc,\n",
    "#         \"final_train_f1\": train_f1,\n",
    "#         \"final_train_precision\": train_precision,\n",
    "#         \"final_train_recall\": train_recall,\n",
    "#         \"final_val_accuracy\": val_acc,\n",
    "#         \"final_val_f1\": val_f1,\n",
    "#         \"final_val_precision\": val_precision,\n",
    "#         \"final_val_recall\": val_recall\n",
    "#     })\n",
    "    \n",
    "#     run.finish()\n",
    "    \n",
    "#     return mlp, val_acc\n",
    "\n",
    "# # Hyperparameter search\n",
    "# def hyperparameter_search(X, y):\n",
    "#     best_model = None\n",
    "#     best_accuracy = 0\n",
    "#     results = []\n",
    "\n",
    "#     hyperparameters = {\n",
    "#         \"hidden_layers\": [[9], [18], [9, 9]],\n",
    "#         \"learning_rate\": [0.001, 0.01, 0.1],\n",
    "#         \"activation\": [\"sigmoid\", \"relu\", \"tanh\"],\n",
    "#         \"optimizer\": [\"sgd\", \"mini_batch\", \"batch\"],\n",
    "#         \"batch_size\": [32, 64, 128],\n",
    "#         \"epochs\": [100, 200]\n",
    "#     }\n",
    "\n",
    "#     for hidden_layers in hyperparameters[\"hidden_layers\"]:\n",
    "#         for learning_rate in hyperparameters[\"learning_rate\"]:\n",
    "#             for activation in hyperparameters[\"activation\"]:\n",
    "#                 for optimizer in hyperparameters[\"optimizer\"]:\n",
    "#                     for batch_size in hyperparameters[\"batch_size\"]:\n",
    "#                         for epochs in hyperparameters[\"epochs\"]:\n",
    "#                             config = {\n",
    "#                                 \"hidden_layers\": hidden_layers,\n",
    "#                                 \"learning_rate\": learning_rate,\n",
    "#                                 \"activation\": activation,\n",
    "#                                 \"optimizer\": optimizer,\n",
    "#                                 \"batch_size\": batch_size,\n",
    "#                                 \"epochs\": epochs\n",
    "#                             }\n",
    "                            \n",
    "#                             # Initialize W&B\n",
    "#                             run = wandb.init(project=\"mlp-wine-quality\", config=config)\n",
    "#                             model, accuracy = run_experiment(run.config, X, y)\n",
    "#                             run.finish()\n",
    "                            \n",
    "#                             results.append({\n",
    "#                                 \"hidden_layers\": hidden_layers,\n",
    "#                                 \"learning_rate\": learning_rate,\n",
    "#                                 \"activation\": activation,\n",
    "#                                 \"optimizer\": optimizer,\n",
    "#                                 \"batch_size\": batch_size,\n",
    "#                                 \"epochs\": epochs,\n",
    "#                                 \"accuracy\": accuracy\n",
    "#                             })\n",
    "                            \n",
    "#                             if accuracy > best_accuracy:\n",
    "#                                 best_accuracy = accuracy\n",
    "#                                 best_model = model\n",
    "\n",
    "#     return best_model, results\n",
    "\n",
    "# # Main execution\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Load your data here\n",
    "#     # X, y = load_wine_quality_data()\n",
    "    \n",
    "#     # Run hyperparameter search\n",
    "#     best_model, results = hyperparameter_search(X, y)\n",
    "    \n",
    "#     # Print results table\n",
    "#     print(\"\\nHyperparameter Search Results:\")\n",
    "#     print(\"-----------------------------\")\n",
    "#     for result in results:\n",
    "#         print(f\"Hidden Layers: {result['hidden_layers']}\")\n",
    "#         print(f\"Learning Rate: {result['learning_rate']}\")\n",
    "#         print(f\"Activation: {result['activation']}\")\n",
    "#         print(f\"Optimizer: {result['optimizer']}\")\n",
    "#         print(f\"Batch Size: {result['batch_size']}\")\n",
    "#         print(f\"Epochs: {result['epochs']}\")\n",
    "#         print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "#         print(\"-----------------------------\")\n",
    "    \n",
    "#     # Print best model parameters\n",
    "#     print(\"\\nBest Model Parameters:\")\n",
    "#     print(f\"Hidden Layers: {best_model.hidden_layers}\")\n",
    "#     print(f\"Learning Rate: {best_model.learning_rate}\")\n",
    "#     print(f\"Activation: {best_model.activation}\")\n",
    "#     print(f\"Optimizer: {best_model.optimizer}\")\n",
    "#     print(f\"Batch Size: {best_model.batch_size}\")\n",
    "#     print(f\"Epochs: {best_model.epochs}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3396\\1350800459.py:138: RuntimeWarning: invalid value encountered in log\n",
      "  cost = -np.sum(y * np.log(activations[-1] + epsilon) + (1 - y) * np.log(1 - activations[-1] + epsilon)) / m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 27\n",
      "Accuracy: 57.89%\n",
      "Average relative error: nan\n",
      "Gradient check passed: False\n"
     ]
    }
   ],
   "source": [
    "# hidden_layer = 64 32\n",
    "# activation relu\n",
    "# batch size 64\n",
    "# early patience 10\n",
    "# epochs 50\n",
    "# learn rate .03026\n",
    "# optimizer sgd\n",
    "# valacc 0.6579\n",
    "\n",
    "mlp=MLP(hidden_layers=[64, 32],\n",
    "            learning_rate=0.03026,\n",
    "            activation='relu',\n",
    "            optimizer='sgd',batch_size=64,\n",
    "            epochs=50)\n",
    "\n",
    "# Fit the model on training data.\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "# Make predictions on the test set.\n",
    "predictions=mlp.predict(X_val)\n",
    "\n",
    "# Calculate accuracy.\n",
    "accuracy_score=mlp.accuracy(y_val,predictions)\n",
    "print(f\"Accuracy: {accuracy_score * 100:.2f}%\")\n",
    "\n",
    "# Perform gradient checking on a sample of test data.\n",
    "is_gradient_correct=mlp.gradient_check(X_val,y_val)\n",
    "print(f\"Gradient check passed: {is_gradient_correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3396\\1350800459.py:138: RuntimeWarning: invalid value encountered in log\n",
      "  cost = -np.sum(y * np.log(activations[-1] + epsilon) + (1 - y) * np.log(1 - activations[-1] + epsilon)) / m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,) (12,64) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# Assuming X_train, y_train, X_val, and y_val are already defined\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     experiment_activation_functions(X_train, y_train, X_val, y_val)\n\u001b[1;32m---> 79\u001b[0m     \u001b[43mexperiment_learning_rates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     experiment_batch_sizes(X_train, y_train, X_val, y_val)\n",
      "Cell \u001b[1;32mIn[33], line 36\u001b[0m, in \u001b[0;36mexperiment_learning_rates\u001b[1;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m learning_rates:\n\u001b[0;32m     31\u001b[0m     mlp\u001b[38;5;241m=\u001b[39mMLP(hidden_layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m32\u001b[39m],\n\u001b[0;32m     32\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39mlearning_rates,\n\u001b[0;32m     33\u001b[0m         activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     34\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m     35\u001b[0m         epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m     \u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(mlp\u001b[38;5;241m.\u001b[39mlosses)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Plotting\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 98\u001b[0m, in \u001b[0;36mMLP.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_samples):\n\u001b[0;32m     97\u001b[0m         dW, db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backpropagation(X_shuffled[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], np\u001b[38;5;241m.\u001b[39meye(n_classes)[y_shuffled[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m---> 98\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    101\u001b[0m     dW, db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backpropagation(X, np\u001b[38;5;241m.\u001b[39meye(n_classes)[y_adjusted])\n",
      "Cell \u001b[1;32mIn[28], line 75\u001b[0m, in \u001b[0;36mMLP._update_parameters\u001b[1;34m(self, dW, db)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m, dW, db):\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)):\n\u001b[1;32m---> 75\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[i] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdW\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases[i] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m db[i]\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,) (12,64) "
     ]
    }
   ],
   "source": [
    "def experiment_activation_functions(X_train, y_train, X_val, y_val):\n",
    "    activation_functions = ['sigmoid', 'tanh', 'relu']\n",
    "    losses = []\n",
    "\n",
    "    for activation in activation_functions:\n",
    "        mlp=MLP(hidden_layers=[64, 32],\n",
    "            learning_rate=0.03026,\n",
    "            activation=activation,\n",
    "            optimizer='sgd',batch_size=64,\n",
    "            epochs=50)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        losses.append(mlp.losses)  # Assuming you store losses in the fit method\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, loss in enumerate(losses):\n",
    "        plt.plot(loss, label=activation_functions[i])\n",
    "    \n",
    "    plt.title('Effect of Non-linearity on Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def experiment_learning_rates(X_train, y_train, X_val, y_val):\n",
    "    learning_rates = [0.001, 0.01, 0.1, 1]\n",
    "    losses = []\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        mlp=MLP(hidden_layers=[64, 32],\n",
    "            learning_rate=learning_rates,\n",
    "            activation='relu',\n",
    "            optimizer='sgd',batch_size=64,\n",
    "            epochs=50)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        losses.append(mlp.losses)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, loss in enumerate(losses):\n",
    "        plt.plot(loss, label=f'LR: {learning_rates[i]}')\n",
    "    \n",
    "    plt.title('Effect of Learning Rate on Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def experiment_batch_sizes(X_train, y_train, X_val, y_val):\n",
    "    batch_sizes = [16, 32, 64, 128]\n",
    "    losses = []\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        mlp=MLP(hidden_layers=[64, 32],\n",
    "            learning_rate=0.03026,\n",
    "            activation='relu',\n",
    "            optimizer='sgd',batch_size=batch_size,\n",
    "            epochs=50)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        losses.append(mlp.losses)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, loss in enumerate(losses):\n",
    "        plt.plot(loss, label=f'Batch Size: {batch_sizes[i]}')\n",
    "    \n",
    "    plt.title('Effect of Batch Size on Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming X_train, y_train, X_val, and y_val are already defined\n",
    "    experiment_activation_functions(X_train, y_train, X_val, y_val)\n",
    "    experiment_learning_rates(X_train, y_train, X_val, y_val)\n",
    "    experiment_batch_sizes(X_train, y_train, X_val, y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Step 1: Load the data\n",
    "file_path = '../../data/external/advertisement.csv'  # Replace with your CSV file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Process the labels\n",
    "# Assuming the last column contains labels in a string format like \"label1 label2 label3\"\n",
    "labels = data.iloc[:, -1].str.get_dummies(sep=' ')  # Convert to one-hot encoding\n",
    "\n",
    "# Step 3: Count label frequencies\n",
    "label_counts = labels.sum().sort_values(ascending=False)\n",
    "\n",
    "# Step 4: Plot the distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(label_counts.index, label_counts.values, color='blue')  # Use a single color like 'blue'\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Label Distribution in Multilabel Classification')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()  # Adjust layout to fit labels\n",
    "plt.show()\n",
    "\n",
    "\n",
    "X = data.iloc[:, :-1].values  # Features\n",
    "y = labels.values  # One-hot encoding for labels\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1].str.split()\n",
    "\n",
    "le = LabelEncoder()\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "unique_labels = set([label for labels in y for label in labels])\n",
    "label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
    "y_encoded = np.zeros((len(y), len(unique_labels)))\n",
    "for i, labels in enumerate(y):\n",
    "    for label in labels:\n",
    "        y_encoded[i, label_to_index[label]] = 1\n",
    "\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.6437\n",
      "Epoch 20/100, Loss: 0.6370\n",
      "Epoch 30/100, Loss: 0.6334\n",
      "Epoch 40/100, Loss: 0.6315\n",
      "Early stopping at epoch 46\n",
      "Accuracy: 0.0300\n",
      "Precision: 0.5862\n",
      "Recall: 0.0661\n",
      "F1-score: 0.1189\n",
      "Hamming Loss: 0.3150\n",
      "\n",
      "Soft Accuracy: 0.6850\n",
      "Performing gradient check...\n",
      "Average relative error: 0.8958998443174107\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, hamming_loss\n",
    "\n",
    "class ActivationFunction:\n",
    "    @staticmethod\n",
    "    def sigmoid(x, derivative=False):\n",
    "        sig = 1 / (1 + np.exp(-np.clip(x, -500, 500)))  # Clip to avoid overflow\n",
    "        return sig * (1 - sig) if derivative else sig\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x, derivative=False):\n",
    "        t = np.tanh(x)\n",
    "        return 1 - t**2 if derivative else t\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x, derivative=False):\n",
    "        return np.where(x > 0, 1, 0) if derivative else np.maximum(0, x)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(x, derivative=False):\n",
    "        return np.ones_like(x) if derivative else x\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, input_size, output_size, activation='relu'):\n",
    "        self.weights = np.random.randn(input_size, output_size) * np.sqrt(2. / input_size)  # He initialization\n",
    "        self.bias = np.zeros((1, output_size))\n",
    "        self.activation = getattr(ActivationFunction, activation)\n",
    "        self.dW = np.zeros_like(self.weights)  # Gradient of weights\n",
    "        self.db = np.zeros_like(self.bias)  # Gradient of bias\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.z = np.dot(inputs, self.weights) + self.bias\n",
    "        return self.activation(self.z)\n",
    "\n",
    "    def backward(self, delta, learning_rate, optimizer):\n",
    "        delta = delta * self.activation(self.z, derivative=True)\n",
    "        self.dW = np.dot(self.inputs.T, delta)\n",
    "        self.db = np.sum(delta, axis=0, keepdims=True)\n",
    "        \n",
    "        if optimizer == 'sgd':\n",
    "            self.weights -= learning_rate * self.dW\n",
    "            self.bias -= learning_rate * self.db\n",
    "        elif optimizer == 'batch':\n",
    "            return self.dW, self.db\n",
    "        \n",
    "        return np.dot(delta, self.weights.T)\n",
    "\n",
    "class AdvancedMultiLabelMLP:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, learning_rate=0.001, \n",
    "                 activation='relu', optimizer='sgd', batch_size=32, epochs=100, early_stopping_pat=5):\n",
    "        self.layers = []\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.early_stopping_patience= early_stopping_pat\n",
    "        \n",
    "        # Input layer\n",
    "        self.layers.append(Layer(input_size, hidden_sizes[0], activation))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            self.layers.append(Layer(hidden_sizes[i-1], hidden_sizes[i], activation))\n",
    "        \n",
    "        # Output layer\n",
    "        self.layers.append(Layer(hidden_sizes[-1], output_size, 'sigmoid'))\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "\n",
    "    def backward(self, X, y, output):\n",
    "        delta = output - y\n",
    "        for layer in reversed(self.layers):\n",
    "            delta = layer.backward(delta, self.learning_rate, self.optimizer)\n",
    "\n",
    "    def fit(self, X, y, validation_data=None):\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            if self.optimizer == 'sgd':\n",
    "                indices = np.random.permutation(len(X))\n",
    "                X = X[indices]\n",
    "                y = y[indices]\n",
    "            \n",
    "            for i in range(0, len(X), self.batch_size):\n",
    "                batch_X = X[i:i+self.batch_size]\n",
    "                batch_y = y[i:i+self.batch_size]\n",
    "                \n",
    "                output = self.forward(batch_X)\n",
    "                self.backward(batch_X, batch_y, output)\n",
    "            \n",
    "            # Early stopping\n",
    "            if validation_data is not None:\n",
    "                val_X, val_y = validation_data\n",
    "                val_output = self.predict(val_X)\n",
    "                val_loss = self.compute_loss(val_y, val_output)\n",
    "                \n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                \n",
    "                if patience_counter >= self.early_stopping_patience:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                loss = self.compute_loss(y, self.predict(X))\n",
    "                print(f\"Epoch {epoch+1}/{self.epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def predict_binary(self, X, threshold=0.5):\n",
    "        probabilities = self.predict(X)\n",
    "        return (probabilities >= threshold).astype(int)\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        return -np.mean(y_true * np.log(y_pred + 1e-8) + (1 - y_true) * np.log(1 - y_pred + 1e-8))\n",
    "\n",
    "    def gradient_check(self, X, y, epsilon=1e-7):\n",
    "    # Compute gradients using backpropagation\n",
    "        output = self.forward(X)\n",
    "        self.backward(X, y, output)\n",
    "        \n",
    "        # Flatten weights and biases separately for easier gradient comparison\n",
    "        params = []\n",
    "        grads = []\n",
    "        for layer in self.layers:\n",
    "            params.append(layer.weights)\n",
    "            params.append(layer.bias)\n",
    "            grads.append(layer.dW)\n",
    "            grads.append(layer.db)\n",
    "        \n",
    "        num_grads = []\n",
    "        \n",
    "        for param in params:\n",
    "            num_grad = np.zeros_like(param)\n",
    "            it = np.nditer(param, flags=['multi_index'], op_flags=['readwrite'])\n",
    "            while not it.finished:\n",
    "                idx = it.multi_index\n",
    "                old_value = param[idx]\n",
    "                \n",
    "                # Compute the cost with the parameter slightly increased\n",
    "                param[idx] = old_value + epsilon\n",
    "                cost_plus = self.compute_loss(y, self.forward(X))\n",
    "                \n",
    "                # Compute the cost with the parameter slightly decreased\n",
    "                param[idx] = old_value - epsilon\n",
    "                cost_minus = self.compute_loss(y, self.forward(X))\n",
    "                \n",
    "                # Calculate numerical gradient\n",
    "                num_grad[idx] = (cost_plus - cost_minus) / (2 * epsilon)\n",
    "                \n",
    "                # Reset the parameter value\n",
    "                param[idx] = old_value\n",
    "                it.iternext()\n",
    "            \n",
    "            num_grads.append(num_grad)\n",
    "        \n",
    "        # Compare backprop gradients with numerical gradients\n",
    "        total_error = 0\n",
    "        for grad, num_grad in zip(grads, num_grads):\n",
    "            numerator = np.linalg.norm(grad - num_grad)\n",
    "            denominator = np.linalg.norm(grad) + np.linalg.norm(num_grad)\n",
    "            total_error += numerator / (denominator + 1e-7)\n",
    "        \n",
    "        average_error = total_error / len(params)\n",
    "        print(f\"Average relative error: {average_error}\")\n",
    "        \n",
    "        return average_error < 1e-7\n",
    "\n",
    "    \n",
    "def preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1].str.split()\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    for column in X.columns:\n",
    "        if X[column].dtype == 'object':\n",
    "            X[column] = le.fit_transform(X[column])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    unique_labels = set([label for labels in y for label in labels])\n",
    "    label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
    "    y_encoded = np.zeros((len(y), len(unique_labels)))\n",
    "    for i, labels in enumerate(y):\n",
    "        for label in labels:\n",
    "            y_encoded[i, label_to_index[label]] = 1\n",
    "    \n",
    "    return X, y_encoded, label_to_index\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='micro')\n",
    "    recall = recall_score(y_true, y_pred, average='micro')\n",
    "    f1 = f1_score(y_true, y_pred, average='micro')\n",
    "    h_loss = hamming_loss(y_true, y_pred)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-score: {f1:.4f}')\n",
    "    print(f'Hamming Loss: {h_loss:.4f}')\n",
    "\n",
    "def calculate_soft_accuracy(y_true, y_pred):\n",
    "    # Count true positives and true negatives\n",
    "    true_positives = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    true_negatives = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    \n",
    "    total = y_true.shape[0] * y_true.shape[1]  # Total number of predictions\n",
    "    \n",
    "    # Calculate soft accuracy\n",
    "    soft_accuracy = (true_positives + true_negatives) / total\n",
    "    return soft_accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Preprocess data\n",
    "    # X, y, label_to_index = preprocess_data(\"advertisement.csv\")\n",
    "    \n",
    "    # # Split the data\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create and train the model\n",
    "    input_size = X_train.shape[1]\n",
    "    hidden_sizes = [9]  # You can modify this to change the number of hidden layers and neurons\n",
    "    output_size = y_train.shape[1]\n",
    "    \n",
    "    model = AdvancedMultiLabelMLP(\n",
    "        input_size=input_size,\n",
    "        hidden_sizes=hidden_sizes,\n",
    "        output_size=output_size,\n",
    "        learning_rate=0.01,\n",
    "        activation='sigmoid',  # You can change this to 'sigmoid', 'tanh', or 'linear'\n",
    "        optimizer='sgd',    # You can change this to 'batch' or 'mini-batch'\n",
    "        batch_size=32,\n",
    "        epochs=100,\n",
    "        early_stopping_pat=5\n",
    "    )\n",
    "    \n",
    "    # Train the model with early stopping\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred_binary = model.predict_binary(X_test)\n",
    "    evaluate_model(y_test, y_pred_binary)\n",
    "\n",
    "    soft_accuracy = calculate_soft_accuracy(y_test, y_pred_binary)\n",
    "    print(f\"\\nSoft Accuracy: {soft_accuracy:.4f}\")\n",
    "\n",
    "    print(\"Performing gradient check...\")\n",
    "    model.gradient_check(X_train[:10], y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: s3ry7u83\n",
      "Sweep URL: https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cat5g7f7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 150\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [9]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08163558451502814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdusaneyash09\u001b[0m (\u001b[33mdusaneyash09-iiit-hyderabad\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_114035-cat5g7f7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/cat5g7f7' target=\"_blank\">sunny-sweep-1</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/cat5g7f7' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/cat5g7f7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150, Loss: 2.5259\n",
      "Early stopping at epoch 17\n",
      "Accuracy: 0.0100, Soft Accuracy: 0.6687\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>soft_accuracy</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>soft_accuracy</td><td>0.66875</td></tr><tr><td>val_accuracy</td><td>0.01</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sunny-sweep-1</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/cat5g7f7' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/cat5g7f7</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_114035-cat5g7f7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1jefbm0c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [64, 32]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02752306460231159\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: mini_batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_114045-1jefbm0c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/1jefbm0c' target=\"_blank\">iconic-sweep-2</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/1jefbm0c' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/1jefbm0c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.8858\n",
      "Early stopping at epoch 16\n",
      "Accuracy: 0.0000, Soft Accuracy: 0.4650\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>soft_accuracy</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>soft_accuracy</td><td>0.465</td></tr><tr><td>val_accuracy</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">iconic-sweep-2</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/1jefbm0c' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/1jefbm0c</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_114045-1jefbm0c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ke1fnc7b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [9]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0039115625804875855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_114051-ke1fnc7b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/ke1fnc7b' target=\"_blank\">zesty-sweep-3</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/ke1fnc7b' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/ke1fnc7b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\1641884746.py\", line 30, in run_experiment\n",
      "    model.fit(X_train, y_train, validation_data=(X_test, y_test), early_stopping_patience=config.early_stopping_patience)\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 96, in fit\n",
      "    self.backward(batch_X, batch_y, output)\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 79, in backward\n",
      "    delta = layer.backward(delta, self.learning_rate, self.optimizer)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 40, in backward\n",
      "    delta = delta * self.activation(self.z, derivative=True)\n",
      "            ~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zesty-sweep-3</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/ke1fnc7b' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/ke1fnc7b</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_114051-ke1fnc7b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run ke1fnc7b errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\agents\\pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\1641884746.py\", line 30, in run_experiment\n",
      "    model.fit(X_train, y_train, validation_data=(X_test, y_test), early_stopping_patience=config.early_stopping_patience)\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 96, in fit\n",
      "    self.backward(batch_X, batch_y, output)\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 79, in backward\n",
      "    delta = layer.backward(delta, self.learning_rate, self.optimizer)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 40, in backward\n",
      "    delta = delta * self.activation(self.z, derivative=True)\n",
      "            ~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ke1fnc7b errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"c:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\agents\\pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\1641884746.py\", line 30, in run_experiment\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model.fit(X_train, y_train, validation_data=(X_test, y_test), early_stopping_patience=config.early_stopping_patience)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 96, in fit\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.backward(batch_X, batch_y, output)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 79, in backward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     delta = layer.backward(delta, self.learning_rate, self.optimizer)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 40, in backward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     delta = delta * self.activation(self.z, derivative=True)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ehgut3bc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 150\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [64, 32]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.014306209864736153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_114056-ehgut3bc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/ehgut3bc' target=\"_blank\">dazzling-sweep-4</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/ehgut3bc' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/ehgut3bc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\1641884746.py\", line 30, in run_experiment\n",
      "    model.fit(X_train, y_train, validation_data=(X_test, y_test), early_stopping_patience=config.early_stopping_patience)\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 96, in fit\n",
      "    self.backward(batch_X, batch_y, output)\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 79, in backward\n",
      "    delta = layer.backward(delta, self.learning_rate, self.optimizer)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 40, in backward\n",
      "    delta = delta * self.activation(self.z, derivative=True)\n",
      "            ~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dazzling-sweep-4</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/ehgut3bc' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/ehgut3bc</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_114056-ehgut3bc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run ehgut3bc errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\agents\\pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\1641884746.py\", line 30, in run_experiment\n",
      "    model.fit(X_train, y_train, validation_data=(X_test, y_test), early_stopping_patience=config.early_stopping_patience)\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 96, in fit\n",
      "    self.backward(batch_X, batch_y, output)\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 79, in backward\n",
      "    delta = layer.backward(delta, self.learning_rate, self.optimizer)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 40, in backward\n",
      "    delta = delta * self.activation(self.z, derivative=True)\n",
      "            ~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ehgut3bc errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"c:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\agents\\pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\1641884746.py\", line 30, in run_experiment\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model.fit(X_train, y_train, validation_data=(X_test, y_test), early_stopping_patience=config.early_stopping_patience)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 96, in fit\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.backward(batch_X, batch_y, output)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 79, in backward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     delta = layer.backward(delta, self.learning_rate, self.optimizer)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 40, in backward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     delta = delta * self.activation(self.z, derivative=True)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 93k2622v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [64, 32]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03765940589735126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: mini_batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_114102-93k2622v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/93k2622v' target=\"_blank\">polished-sweep-5</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/93k2622v' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/93k2622v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.8726\n",
      "Early stopping at epoch 16\n",
      "Accuracy: 0.0000, Soft Accuracy: 0.4913\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>soft_accuracy</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>soft_accuracy</td><td>0.49125</td></tr><tr><td>val_accuracy</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polished-sweep-5</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/93k2622v' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/93k2622v</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_114102-93k2622v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7smsgize with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [64, 32]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.030853775563808535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: mini_batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_114107-7smsgize</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/7smsgize' target=\"_blank\">dutiful-sweep-6</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/7smsgize' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/7smsgize</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.8115\n",
      "Early stopping at epoch 11\n",
      "Accuracy: 0.0100, Soft Accuracy: 0.5225\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>soft_accuracy</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>soft_accuracy</td><td>0.5225</td></tr><tr><td>val_accuracy</td><td>0.01</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-sweep-6</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/7smsgize' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/7smsgize</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_114107-7smsgize\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9jjp5rzn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 150\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [9]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03210959839945258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_114113-9jjp5rzn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/9jjp5rzn' target=\"_blank\">lemon-sweep-7</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/9jjp5rzn' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/9jjp5rzn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150, Loss: 0.6269\n",
      "Early stopping at epoch 18\n",
      "Accuracy: 0.0200, Soft Accuracy: 0.6663\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>soft_accuracy</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>soft_accuracy</td><td>0.66625</td></tr><tr><td>val_accuracy</td><td>0.02</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lemon-sweep-7</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/9jjp5rzn' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/9jjp5rzn</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_114113-9jjp5rzn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5wqjz7px with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [10, 8]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07806959556823369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: mini_batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_114118-5wqjz7px</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/5wqjz7px' target=\"_blank\">glad-sweep-8</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/5wqjz7px' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/5wqjz7px</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.9593\n",
      "Early stopping at epoch 16\n",
      "Accuracy: 0.0100, Soft Accuracy: 0.5225\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>soft_accuracy</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>soft_accuracy</td><td>0.5225</td></tr><tr><td>val_accuracy</td><td>0.01</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glad-sweep-8</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/5wqjz7px' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/5wqjz7px</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_114118-5wqjz7px\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m2rfhiw2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [9]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.012338327813370603\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_114124-m2rfhiw2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/m2rfhiw2' target=\"_blank\">dandy-sweep-9</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/m2rfhiw2' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/m2rfhiw2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.6330\n",
      "Epoch 20/50, Loss: 0.6270\n",
      "Early stopping at epoch 26\n",
      "Accuracy: 0.0600, Soft Accuracy: 0.6887\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>soft_accuracy</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>soft_accuracy</td><td>0.68875</td></tr><tr><td>val_accuracy</td><td>0.06</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dandy-sweep-9</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/m2rfhiw2' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/m2rfhiw2</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_114124-m2rfhiw2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y1grrngq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stopping_patience: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [10, 8]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06652211040123382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_114129-y1grrngq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/y1grrngq' target=\"_blank\">dazzling-sweep-10</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/sweeps/s3ry7u83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/y1grrngq' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/y1grrngq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\1641884746.py\", line 30, in run_experiment\n",
      "    model.fit(X_train, y_train, validation_data=(X_test, y_test), early_stopping_patience=config.early_stopping_patience)\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 96, in fit\n",
      "    self.backward(batch_X, batch_y, output)\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 79, in backward\n",
      "    delta = layer.backward(delta, self.learning_rate, self.optimizer)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 40, in backward\n",
      "    delta = delta * self.activation(self.z, derivative=True)\n",
      "            ~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dazzling-sweep-10</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/y1grrngq' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp/runs/y1grrngq</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/multi_label_mlp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_114129-y1grrngq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run y1grrngq errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\agents\\pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\1641884746.py\", line 30, in run_experiment\n",
      "    model.fit(X_train, y_train, validation_data=(X_test, y_test), early_stopping_patience=config.early_stopping_patience)\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 96, in fit\n",
      "    self.backward(batch_X, batch_y, output)\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 79, in backward\n",
      "    delta = layer.backward(delta, self.learning_rate, self.optimizer)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 40, in backward\n",
      "    delta = delta * self.activation(self.z, derivative=True)\n",
      "            ~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run y1grrngq errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"c:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\agents\\pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\1641884746.py\", line 30, in run_experiment\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model.fit(X_train, y_train, validation_data=(X_test, y_test), early_stopping_patience=config.early_stopping_patience)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 96, in fit\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.backward(batch_X, batch_y, output)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 79, in backward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     delta = layer.backward(delta, self.learning_rate, self.optimizer)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"C:\\Users\\yashd\\AppData\\Local\\Temp\\ipykernel_3288\\2170164406.py\", line 40, in backward\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     delta = delta * self.activation(self.z, derivative=True)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize a new run at the start of training\n",
    "def run_experiment(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        \n",
    "        # Preprocess data\n",
    "        # X, y, label_to_index = preprocess_data(\"advertisement.csv\")\n",
    "        \n",
    "        # Split the data\n",
    "        # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        input_size = X_train.shape[1]\n",
    "        output_size = y_train.shape[1]\n",
    "        \n",
    "        # Initialize model with hyperparameters from config\n",
    "        model = AdvancedMultiLabelMLP(\n",
    "            input_size=input_size,\n",
    "            hidden_sizes=config.hidden_layers,\n",
    "            output_size=output_size,\n",
    "            learning_rate=config.learning_rate,\n",
    "            activation=config.activation,\n",
    "            optimizer=config.optimizer,\n",
    "            batch_size=config.batch_size,\n",
    "            epochs=config.epochs\n",
    "        )\n",
    "        \n",
    "        # Train the model with early stopping\n",
    "        model.fit(X_train, y_train, validation_data=(X_test, y_test), early_stopping_patience=config.early_stopping_patience)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        y_pred_binary = model.predict_binary(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "        soft_accuracy = calculate_soft_accuracy(y_test, y_pred_binary)\n",
    "        \n",
    "        # Log metrics to WandB\n",
    "        wandb.log({\n",
    "            \"val_accuracy\": accuracy,\n",
    "            \"soft_accuracy\": soft_accuracy\n",
    "        })\n",
    "\n",
    "        print(f\"Accuracy: {accuracy:.4f}, Soft Accuracy: {soft_accuracy:.4f}\")\n",
    "\n",
    "# Define the sweep configuration\n",
    "sweep_configuration = {\n",
    "    'method': 'random',\n",
    "    'name': 'sweep',\n",
    "    'metric': {'goal': 'maximize', 'name': 'soft_accuracy'},\n",
    "    'parameters': \n",
    "    {\n",
    "        'hidden_layers': {'values': [[9], [10, 8], [64, 32]]},\n",
    "        'learning_rate': {'min': 0.0001, 'max': 0.1},\n",
    "        'activation': {'values': ['sigmoid', 'relu', 'tanh']},\n",
    "        'optimizer': {'values': ['sgd', 'batch', 'mini_batch']},\n",
    "        'batch_size': {'values': [16, 32, 64]},\n",
    "        'epochs': {'values': [50, 100, 150]},\n",
    "        'early_stopping_patience': {'values': [5, 10, 15]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize the sweep\n",
    "sweep_id = wandb.sweep(sweep_configuration, project=\"multi_label_mlp\")\n",
    "\n",
    "# Run the sweep\n",
    "wandb.agent(sweep_id, function=run_experiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.6333\n",
      "Epoch 20/50, Loss: 0.6284\n",
      "Epoch 30/50, Loss: 0.6252\n",
      "Epoch 40/50, Loss: 0.6221\n",
      "Early stopping at epoch 42\n",
      "Accuracy: 0.0500\n",
      "Precision: 0.5085\n",
      "Recall: 0.1167\n",
      "F1-score: 0.1899\n",
      "Hamming Loss: 0.3200\n",
      "\n",
      "Soft Accuracy: 0.6800\n"
     ]
    }
   ],
   "source": [
    "model = AdvancedMultiLabelMLP(\n",
    "        input_size=input_size,\n",
    "        hidden_sizes=[9],\n",
    "        output_size=output_size,\n",
    "        learning_rate=0.01234,\n",
    "        activation='relu',  # You can change this to 'sigmoid', 'tanh', or 'linear'\n",
    "        optimizer='sgd',    # You can change this to 'batch' or 'mini-batch'\n",
    "        batch_size=16,\n",
    "        epochs=50,\n",
    "        early_stopping_pat=5\n",
    "    )\n",
    "    \n",
    "# Train the model with early stopping\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_binary = model.predict_binary(X_test)\n",
    "evaluate_model(y_test, y_pred_binary)\n",
    "\n",
    "soft_accuracy = calculate_soft_accuracy(y_test, y_pred_binary)\n",
    "print(f\"\\nSoft Accuracy: {soft_accuracy:.4f}\")\n",
    "\n",
    "# print(\"Performing gradient check...\")\n",
    "# model.gradient_check(X_train[:10], y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "### Question 3 MLP Regression\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          NOX          RM        DIS             RAD         TAX     PTRATIO   \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     0.554695    6.284634    3.795043    9.549407  408.237154   18.455534   \n",
      "std      0.115878    0.702617    2.105710    8.707259  168.537116    2.164946   \n",
      "min      0.385000    3.561000    1.129600    1.000000  187.000000   12.600000   \n",
      "25%      0.449000    5.885500    2.100175    4.000000  279.000000   17.400000   \n",
      "50%      0.538000    6.208500    3.207450    5.000000  330.000000   19.050000   \n",
      "75%      0.624000    6.623500    5.188425   24.000000  666.000000   20.200000   \n",
      "max      0.871000    8.780000   12.126500   24.000000  711.000000   22.000000   \n",
      "\n",
      "          B              MEDV  \n",
      "count  506.000000  506.000000  \n",
      "mean   356.674032   22.532806  \n",
      "std     91.294864    9.197104  \n",
      "min      0.320000    5.000000  \n",
      "25%    375.377500   17.025000  \n",
      "50%    391.440000   21.200000  \n",
      "75%    396.225000   25.000000  \n",
      "max    396.900000   50.000000  \n",
      "Missing values in each column:\n",
      " CRIM        20\n",
      "ZN          20\n",
      "INDUS       20\n",
      "CHAS        20\n",
      "NOX          0\n",
      "RM           0\n",
      "AGE         20\n",
      "DIS          0\n",
      "RAD          0\n",
      "TAX          0\n",
      "PTRATIO      0\n",
      "B            0\n",
      "LSTAT       20\n",
      "MEDV         0\n",
      "dtype: int64\n",
      "Missing values after handling:\n",
      " CRIM        0\n",
      "ZN          0\n",
      "INDUS       0\n",
      "CHAS        0\n",
      "NOX         0\n",
      "RM          0\n",
      "AGE         0\n",
      "DIS         0\n",
      "RAD         0\n",
      "TAX         0\n",
      "PTRATIO     0\n",
      "B           0\n",
      "LSTAT       0\n",
      "MEDV        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (236, 14)\n",
      "Validation set: (79, 14)\n",
      "Test set: (79, 14)\n",
      "Scaled training data mean: [-1.12904036e-17 -2.25808073e-17  7.52693576e-17  6.02154861e-17\n",
      "  1.50538715e-16 -1.23441746e-15  1.65592587e-16  5.26885503e-17\n",
      " -6.02154861e-17 -1.12904036e-16  1.27957908e-15 -1.58065651e-16\n",
      " -1.65592587e-16]\n",
      "Scaled training data std: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from CSV\n",
    "df = pd.read_csv('../../data/external/HousingData.csv')\n",
    "\n",
    "# Describe the dataset\n",
    "description = df.describe()\n",
    "print(description)\n",
    "\n",
    "# Replace 'NA' with NaN\n",
    "df.replace('NA', pd.NA, inplace=True)\n",
    "\n",
    "# Convert relevant columns to numeric (if they aren't already)\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Check again for missing values\n",
    "missing_values_after = df.isnull().sum()\n",
    "print(\"Missing values after handling:\\n\", missing_values_after)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of MEDV\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['MEDV'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Housing Prices (MEDV)')\n",
    "plt.xlabel('MEDV (in $1000s)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_val, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train, val = train_test_split(train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Check the shapes of the splits\n",
    "print(f'Train set: {train.shape}')\n",
    "print(f'Validation set: {val.shape}')\n",
    "print(f'Test set: {test.shape}')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separating features and target\n",
    "X_train = train.drop('MEDV', axis=1)\n",
    "y_train = train['MEDV']\n",
    "X_val = val.drop('MEDV', axis=1)\n",
    "y_val = val['MEDV']\n",
    "X_test = test.drop('MEDV', axis=1)\n",
    "y_test = test['MEDV']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform all sets\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Check the scaled values\n",
    "print(f'Scaled training data mean: {X_train.mean(axis=0)}')\n",
    "print(f'Scaled training data std: {X_train.std(axis=0)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 3.1579, RMSE: 1.7770, R²: -5.8537\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLPRegression:\n",
    "    def __init__(self, layers, learning_rate=0.01, activation='relu', optimizer='sgd', batch_size=32, epochs=100):\n",
    "        self.layers = layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation_func = self.get_activation_func(activation)\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.weights, self.biases = self.initialize_weights()\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        np.random.seed(42)\n",
    "        weights = []\n",
    "        biases = []\n",
    "        for i in range(1, len(self.layers)):\n",
    "            weights.append(np.random.randn(self.layers[i], self.layers[i - 1]) * 0.01)\n",
    "            biases.append(np.zeros((self.layers[i], 1)))\n",
    "        return weights, biases\n",
    "\n",
    "    def get_activation_func(self, name):\n",
    "        if name == 'sigmoid':\n",
    "            return lambda x: 1 / (1 + np.exp(-np.clip(x, -500, 500))), lambda x: x * (1 - x)  # Clipping the input to avoid overflow\n",
    "        elif name == 'tanh':\n",
    "            return lambda x: np.tanh(x), lambda x: 1 - x ** 2  # Tanh & derivative\n",
    "        elif name == 'relu':\n",
    "            return lambda x: np.maximum(0, x), lambda x: np.where(x > 0, 1, 0)  # ReLU & derivative\n",
    "        elif name == 'linear':\n",
    "            return lambda x: x, lambda x: 1  # Linear (for regression)\n",
    "    x: 1  # Linear (for regression)\n",
    "\n",
    "    def forward(self, X):\n",
    "        a = X.T\n",
    "        activations = [a]\n",
    "        z_values = []\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w, a) + b\n",
    "            a = self.activation_func[0](z)\n",
    "            z_values.append(z)\n",
    "            activations.append(a)\n",
    "        return activations, z_values\n",
    "\n",
    "    def backprop(self, activations, z_values, y):\n",
    "        m = y.shape[0]\n",
    "        dz = activations[-1] - y.T\n",
    "        dws = []\n",
    "        dbs = []\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            dw = (1/m) * np.dot(dz, activations[i].T)\n",
    "            db = (1/m) * np.sum(dz, axis=1, keepdims=True)\n",
    "\n",
    "            # Gradient Clipping: Limit the values of dw and db to a certain threshold\n",
    "            np.clip(dw, -1e5, 1e5, out=dw)\n",
    "            np.clip(db, -1e5, 1e5, out=db)\n",
    "\n",
    "            dws.insert(0, dw)\n",
    "            dbs.insert(0, db)\n",
    "            if i > 0:\n",
    "                dz = np.dot(self.weights[i].T, dz) * self.activation_func[1](z_values[i-1])  # Backpropagate\n",
    "        return dws, dbs\n",
    "\n",
    "\n",
    "    def update_weights(self, dws, dbs):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * dws[i]\n",
    "            self.biases[i] -= self.learning_rate * dbs[i]\n",
    "\n",
    "    def update_weights_batch(self, X_train, y_train):\n",
    " \n",
    "        y_train = np.array(y_train).reshape(-1, 1)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            activations, z_values = self.forward(X_train)\n",
    "            dws, dbs = self.backprop(activations, z_values, y_train)\n",
    "            self.update_weights(dws, dbs)\n",
    "\n",
    "\n",
    "    def update_weights_mini_batch(self, X_train, y_train):\n",
    "        for epoch in range(self.epochs):\n",
    "            for start_idx in range(0, len(X_train), self.batch_size):\n",
    "                end_idx = start_idx + self.batch_size\n",
    "                X_batch = X_train[start_idx:end_idx]\n",
    "                y_batch = np.array(y_train[start_idx:end_idx]).reshape(-1, 1)  # Ensure proper shape\n",
    "\n",
    "                activations, z_values = self.forward(X_batch)\n",
    "                dws, dbs = self.backprop(activations, z_values, y_batch)\n",
    "                self.update_weights(dws, dbs)\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        if self.optimizer == 'sgd':\n",
    "            self.update_weights_batch(X_train, y_train)\n",
    "        elif self.optimizer == 'batch':\n",
    "            self.update_weights_batch(X_train, y_train)\n",
    "        elif self.optimizer == 'mini_batch':\n",
    "            self.update_weights_mini_batch(X_train, y_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        activations, _ = self.forward(X)\n",
    "        return activations[-1].T\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        y = np.array(y).reshape(-1, 1)\n",
    "        y_pred = self.predict(X)\n",
    "\n",
    "        # Ensure no divide by zero in loss calculation\n",
    "        mae = np.mean((y - y_pred))\n",
    "        mse = np.mean((y - y_pred) ** 2)\n",
    "        if np.isnan(mse) or np.isinf(mse):\n",
    "            print(\"MSE computation resulted in NaN or Inf.\")\n",
    "            mse = np.nan_to_num(mse, nan=1e6, posinf=1e6, neginf=-1e6)  # Avoid NaN or Inf by substituting large values\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = 1 - (np.sum((y - y_pred) ** 2) / (np.sum((y - np.mean(y)) ** 2) + 1e-8))  # Small epsilon to avoid division by zero\n",
    "        return mse, rmse, r2, mae\n",
    "\n",
    "\n",
    "    def gradient_check(self, X, y, epsilon=1e-7):\n",
    "        activations, _ = self.forward(X)\n",
    "        dws, dbs = self.backprop(activations, None, y)\n",
    "        \n",
    "        # Gradient checking for weights\n",
    "        for i in range(len(self.weights)):\n",
    "            original_weights = self.weights[i].copy()\n",
    "            num_grads_w = np.zeros_like(self.weights[i])\n",
    "            \n",
    "            for j in range(self.weights[i].shape[0]):\n",
    "                for k in range(self.weights[i].shape[1]):\n",
    "                    self.weights[i][j, k] += epsilon\n",
    "                    loss1 = self._compute_loss(X, y)\n",
    "                    \n",
    "                    self.weights[i][j, k] -= 2 * epsilon\n",
    "                    loss2 = self._compute_loss(X, y)\n",
    "                    \n",
    "                    num_grads_w[j, k] = (loss1 - loss2) / (2 * epsilon)\n",
    "                    self.weights[i][j, k] = original_weights[j, k]  # Reset\n",
    "            \n",
    "            assert np.allclose(dws[i], num_grads_w, atol=1e-5), f\"Gradient check failed for layer {i}\"\n",
    "        \n",
    "        print(\"Gradient check passed for weights\")\n",
    "\n",
    "    def _compute_loss(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean((y - y_pred) ** 2)\n",
    "\n",
    "\n",
    "# Define the architecture of the MLP\n",
    "layers = [X_train.shape[1], 64, 32, 1]  # Input layer, two hidden layers, output layer\n",
    "\n",
    "# Create an instance of the MLPRegression class\n",
    "mlp = MLPRegression(layers=layers, learning_rate=0.01, activation='relu', optimizer='sgd', batch_size=32, epochs=100)\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "mse_val, rmse_val, r2_val, mae_val = mlp.evaluate(X_val, y_val)\n",
    "print(f'Validation MSE: {mse_val:.4f}, RMSE: {rmse_val:.4f}, R²: {r2_val:.4f}')\n",
    "\n",
    "# mlp.gradient_check(X_val[:10], y_val[:10])\n",
    "# # Evaluate on test set\n",
    "# mse_test, rmse_test, r2_test = mlp.evaluate(X_test, y_test)\n",
    "# print(f'Test MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, R²: {r2_test:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 5.2147, RMSE: 2.2836, R²: -7.0248, MAE: 2.1366\n"
     ]
    }
   ],
   "source": [
    "# Define the architecture of the MLP\n",
    "layers = [X_train.shape[1], 13, 10, 1]  # Input layer, two hidden layers, output layer\n",
    "\n",
    "# Create an instance of the MLPRegression class\n",
    "mlp = MLPRegression(layers=layers, learning_rate=0.01935, activation='relu', optimizer='batch', batch_size=64, epochs=50)\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "mse_test, rmse_test, r2_test, mae_test = mlp.evaluate(X_test, y_test)\n",
    "print(f'Validation MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}, R²: {r2_test:.4f}, MAE: {mae_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 6gjni9g3\n",
      "Sweep URL: https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2mzfq1hq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 64, 32, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09225654079334918\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203744-2mzfq1hq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/2mzfq1hq' target=\"_blank\">brisk-sweep-1</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/2mzfq1hq' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/2mzfq1hq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>530.09114</td></tr><tr><td>RMSE</td><td>23.02371</td></tr><tr><td>R²</td><td>-5.74336</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">brisk-sweep-1</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/2mzfq1hq' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/2mzfq1hq</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203744-2mzfq1hq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dgf9fcn8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 32, 16, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08341886725752752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203756-dgf9fcn8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/dgf9fcn8' target=\"_blank\">sweet-sweep-2</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/dgf9fcn8' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/dgf9fcn8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>558.94177</td></tr><tr><td>RMSE</td><td>23.64195</td></tr><tr><td>R²</td><td>-6.11037</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweet-sweep-2</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/dgf9fcn8' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/dgf9fcn8</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203756-dgf9fcn8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p3ukgzfi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 10, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08816095445399691\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203812-p3ukgzfi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/p3ukgzfi' target=\"_blank\">sage-sweep-3</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/p3ukgzfi' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/p3ukgzfi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>530.09114</td></tr><tr><td>RMSE</td><td>23.02371</td></tr><tr><td>R²</td><td>-5.74336</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sage-sweep-3</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/p3ukgzfi' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/p3ukgzfi</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203812-p3ukgzfi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oebasmcm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 10, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.022746996895633448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: mini-batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203817-oebasmcm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/oebasmcm' target=\"_blank\">dutiful-sweep-4</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/oebasmcm' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/oebasmcm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>551.75188</td></tr><tr><td>RMSE</td><td>23.4894</td></tr><tr><td>R²</td><td>-6.01891</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-sweep-4</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/oebasmcm' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/oebasmcm</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203817-oebasmcm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7r5jrenn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 64, 32, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.022622509146604287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203833-7r5jrenn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/7r5jrenn' target=\"_blank\">fanciful-sweep-5</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/7r5jrenn' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/7r5jrenn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>530.09114</td></tr><tr><td>RMSE</td><td>23.02371</td></tr><tr><td>R²</td><td>-5.74336</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fanciful-sweep-5</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/7r5jrenn' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/7r5jrenn</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203833-7r5jrenn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qv3nndxv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 10, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0634118654732294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: mini-batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203839-qv3nndxv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/qv3nndxv' target=\"_blank\">expert-sweep-6</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/qv3nndxv' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/qv3nndxv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>573.6121</td></tr><tr><td>RMSE</td><td>23.9502</td></tr><tr><td>R²</td><td>-6.297</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">expert-sweep-6</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/qv3nndxv' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/qv3nndxv</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203839-qv3nndxv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gvindu8r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 32, 16, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.026090165504999537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203844-gvindu8r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/gvindu8r' target=\"_blank\">graceful-sweep-7</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/gvindu8r' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/gvindu8r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>530.09114</td></tr><tr><td>RMSE</td><td>23.02371</td></tr><tr><td>R²</td><td>-5.74336</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">graceful-sweep-7</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/gvindu8r' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/gvindu8r</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203844-gvindu8r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: byvh1v7c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 32, 16, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02380411341148807\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203849-byvh1v7c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/byvh1v7c' target=\"_blank\">fresh-sweep-8</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/byvh1v7c' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/byvh1v7c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>25.12549</td></tr><tr><td>RMSE</td><td>5.01253</td></tr><tr><td>R²</td><td>0.68038</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-sweep-8</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/byvh1v7c' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/byvh1v7c</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203849-byvh1v7c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3obxywbh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 64, 32, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.007428424607899751\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203855-3obxywbh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/3obxywbh' target=\"_blank\">drawn-sweep-9</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/3obxywbh' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/3obxywbh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>530.09114</td></tr><tr><td>RMSE</td><td>23.02371</td></tr><tr><td>R²</td><td>-5.74336</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">drawn-sweep-9</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/3obxywbh' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/3obxywbh</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203855-3obxywbh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b3qbfaaw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 10, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.097716266337565\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203900-b3qbfaaw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/b3qbfaaw' target=\"_blank\">distinctive-sweep-10</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/b3qbfaaw' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/b3qbfaaw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>573.58734</td></tr><tr><td>RMSE</td><td>23.94968</td></tr><tr><td>R²</td><td>-6.29668</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distinctive-sweep-10</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/b3qbfaaw' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/b3qbfaaw</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203900-b3qbfaaw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a3nspoae with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 32, 16, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.013550020920275569\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: mini-batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203906-a3nspoae</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/a3nspoae' target=\"_blank\">different-sweep-11</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/a3nspoae' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/a3nspoae</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>573.58667</td></tr><tr><td>RMSE</td><td>23.94967</td></tr><tr><td>R²</td><td>-6.29667</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">different-sweep-11</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/a3nspoae' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/a3nspoae</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203906-a3nspoae\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 06dwgv6s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 10, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01934728134045288\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203911-06dwgv6s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/06dwgv6s' target=\"_blank\">frosty-sweep-12</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/06dwgv6s' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/06dwgv6s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>21.15975</td></tr><tr><td>RMSE</td><td>4.59997</td></tr><tr><td>R²</td><td>0.73082</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">frosty-sweep-12</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/06dwgv6s' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/06dwgv6s</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203911-06dwgv6s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 70oy0av4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 10, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05052759707114166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203916-70oy0av4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/70oy0av4' target=\"_blank\">noble-sweep-13</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/70oy0av4' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/70oy0av4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>530.27326</td></tr><tr><td>RMSE</td><td>23.02766</td></tr><tr><td>R²</td><td>-5.74568</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">noble-sweep-13</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/70oy0av4' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/70oy0av4</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203916-70oy0av4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: up0g05ld with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 64, 32, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0843309949424094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203922-up0g05ld</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/up0g05ld' target=\"_blank\">major-sweep-14</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/up0g05ld' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/up0g05ld</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>559.98481</td></tr><tr><td>RMSE</td><td>23.664</td></tr><tr><td>R²</td><td>-6.12364</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">major-sweep-14</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/up0g05ld' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/up0g05ld</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203922-up0g05ld\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8v2kwsbc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 64, 32, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06707557464991765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203938-8v2kwsbc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/8v2kwsbc' target=\"_blank\">worldly-sweep-15</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/8v2kwsbc' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/8v2kwsbc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>530.09114</td></tr><tr><td>RMSE</td><td>23.02371</td></tr><tr><td>R²</td><td>-5.74336</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worldly-sweep-15</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/8v2kwsbc' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/8v2kwsbc</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203938-8v2kwsbc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2ikpb1l8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 64, 32, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.016058995808151313\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203943-2ikpb1l8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/2ikpb1l8' target=\"_blank\">fancy-sweep-16</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/2ikpb1l8' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/2ikpb1l8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>530.09114</td></tr><tr><td>RMSE</td><td>23.02371</td></tr><tr><td>R²</td><td>-5.74336</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fancy-sweep-16</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/2ikpb1l8' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/2ikpb1l8</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203943-2ikpb1l8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e87usajq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 10, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02050334695216944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_203949-e87usajq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/e87usajq' target=\"_blank\">skilled-sweep-17</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/e87usajq' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/e87usajq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>557.57468</td></tr><tr><td>RMSE</td><td>23.61302</td></tr><tr><td>R²</td><td>-6.09298</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">skilled-sweep-17</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/e87usajq' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/e87usajq</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_203949-e87usajq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yanqswuf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 64, 32, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.024765625744138348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_204005-yanqswuf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/yanqswuf' target=\"_blank\">deft-sweep-18</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/yanqswuf' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/yanqswuf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>34.83694</td></tr><tr><td>RMSE</td><td>5.90228</td></tr><tr><td>R²</td><td>0.55683</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deft-sweep-18</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/yanqswuf' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/yanqswuf</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_204005-yanqswuf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zk8llvoy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 10, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03193106311725523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: mini-batch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_204021-zk8llvoy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/zk8llvoy' target=\"_blank\">lyric-sweep-19</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/zk8llvoy' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/zk8llvoy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>573.6121</td></tr><tr><td>RMSE</td><td>23.9502</td></tr><tr><td>R²</td><td>-6.297</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-19</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/zk8llvoy' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/zk8llvoy</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_204021-zk8llvoy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: blf4vjvs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [13, 10, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07692526846857653\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\yashd\\OneDrive\\Desktop\\IIIT_Hyd\\Sem_5\\SMAI\\github\\assignments\\3\\wandb\\run-20241011_204037-blf4vjvs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/blf4vjvs' target=\"_blank\">visionary-sweep-20</a></strong> to <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/sweeps/6gjni9g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/blf4vjvs' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/blf4vjvs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>▁</td></tr><tr><td>RMSE</td><td>▁</td></tr><tr><td>R²</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE</td><td>557.57468</td></tr><tr><td>RMSE</td><td>23.61302</td></tr><tr><td>R²</td><td>-6.09298</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">visionary-sweep-20</strong> at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/blf4vjvs' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep/runs/blf4vjvs</a><br/> View project at: <a href='https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep' target=\"_blank\">https://wandb.ai/dusaneyash09-iiit-hyderabad/MLP-Regression-Sweep</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241011_204037-blf4vjvs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb \n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'random',  # 'random', 'grid', or 'bayes'\n",
    "    'metric': {\n",
    "        'name': 'MSE',\n",
    "        'goal': 'minimize'  # We want to minimize MSE\n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {'min': 0.0001, 'max': 0.1},\n",
    "        'optimizer': {\n",
    "            'values': ['sgd', 'batch', 'mini-batch']  # Testing SGD and Adam\n",
    "        },\n",
    "        'activation': {\n",
    "            'values': ['relu', 'tanh', 'sigmoid']  # Trying different activation functions\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [16, 32, 64]  # Different batch sizes\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [50, 100, 200]  # Number of epochs\n",
    "        },\n",
    "        'layers': {\n",
    "            'values': [[X_train.shape[1], 64, 32, 1], [X_train.shape[1], 10, 1], [X_train.shape[1], 32, 16, 1]]  # Different network architectures\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def sweep_train():\n",
    "    # Initialize a new run\n",
    "    wandb.init()\n",
    "\n",
    "    # Get hyperparameters from the W&B config\n",
    "    config = wandb.config\n",
    "\n",
    "    # Create the MLP model with hyperparameters from the sweep config\n",
    "    mlp = MLPRegression(\n",
    "        layers=config.layers,\n",
    "        learning_rate=config.learning_rate,\n",
    "        activation=config.activation,\n",
    "        optimizer=config.optimizer,\n",
    "        batch_size=config.batch_size,\n",
    "        epochs=config.epochs\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    mse, rmse, r2 = mlp.evaluate(X_val, y_val)\n",
    "\n",
    "    # Log metrics to W&B\n",
    "    wandb.log({\"MSE\": mse, \"RMSE\": rmse, \"R²\": r2})\n",
    "\n",
    "# Initialize the sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"MLP-Regression-Sweep\")\n",
    "\n",
    "# Run the sweep\n",
    "wandb.agent(sweep_id, function=sweep_train, count=20)  # count defines how many runs to execute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "data = pd.read_csv('../../data/external/diabetes.csv')\n",
    "\n",
    "X = data.iloc[:, :-1].values  # All columns except the last\n",
    "y = data.iloc[:, -1].values   # Last column\n",
    "\n",
    "\n",
    "X_train, X_testval, y_train, y_testval = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_testval, y_testval, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6936022302506661\n",
      "Epoch 10, Loss: 0.6905839921135517\n",
      "Epoch 20, Loss: 0.6876212131673527\n",
      "Epoch 30, Loss: 0.6847128094010263\n",
      "Epoch 40, Loss: 0.6818577098537895\n",
      "Epoch 50, Loss: 0.6790548571162606\n",
      "Epoch 60, Loss: 0.6763032077838926\n",
      "Epoch 70, Loss: 0.6736017328640045\n",
      "Epoch 80, Loss: 0.6709494181378285\n",
      "Epoch 90, Loss: 0.6683452644790988\n",
      "Epoch 100, Loss: 0.6657882881307827\n",
      "Epoch 110, Loss: 0.6632775209416332\n",
      "Epoch 120, Loss: 0.6608120105642898\n",
      "Epoch 130, Loss: 0.6583908206166984\n",
      "Epoch 140, Loss: 0.6560130308086466\n",
      "Epoch 150, Loss: 0.6536777370352286\n",
      "Epoch 160, Loss: 0.6513840514390549\n",
      "Epoch 170, Loss: 0.6491311024430161\n",
      "Epoch 180, Loss: 0.646918034755396\n",
      "Epoch 190, Loss: 0.6447440093491013\n",
      "Epoch 200, Loss: 0.6426082034167473\n",
      "Epoch 210, Loss: 0.6405098103032957\n",
      "Epoch 220, Loss: 0.6384480394178997\n",
      "Epoch 230, Loss: 0.6364221161265613\n",
      "Epoch 240, Loss: 0.6344312816271505\n",
      "Epoch 250, Loss: 0.6324747928082832\n",
      "Epoch 260, Loss: 0.6305519220934906\n",
      "Epoch 270, Loss: 0.6286619572720563\n",
      "Epoch 280, Loss: 0.6268042013178307\n",
      "Epoch 290, Loss: 0.6249779721972734\n",
      "Epoch 300, Loss: 0.6231826026679056\n",
      "Epoch 310, Loss: 0.6214174400682956\n",
      "Epoch 320, Loss: 0.6196818461006345\n",
      "Epoch 330, Loss: 0.6179751966069001\n",
      "Epoch 340, Loss: 0.6162968813395436\n",
      "Epoch 350, Loss: 0.614646303727574\n",
      "Epoch 360, Loss: 0.613022880638862\n",
      "Epoch 370, Loss: 0.6114260421394236\n",
      "Epoch 380, Loss: 0.6098552312503926\n",
      "Epoch 390, Loss: 0.6083099037033399\n",
      "Epoch 400, Loss: 0.6067895276945448\n",
      "Epoch 410, Loss: 0.6052935836387804\n",
      "Epoch 420, Loss: 0.6038215639231258\n",
      "Epoch 430, Loss: 0.6023729726612765\n",
      "Epoch 440, Loss: 0.6009473254487835\n",
      "Epoch 450, Loss: 0.599544149119614\n",
      "Epoch 460, Loss: 0.5981629815043874\n",
      "Epoch 470, Loss: 0.5968033711906086\n",
      "Epoch 480, Loss: 0.5954648772851869\n",
      "Epoch 490, Loss: 0.5941470691795007\n",
      "Epoch 500, Loss: 0.5928495263172341\n",
      "Epoch 510, Loss: 0.5915718379651949\n",
      "Epoch 520, Loss: 0.5903136029872886\n",
      "Epoch 530, Loss: 0.5890744296218068\n",
      "Epoch 540, Loss: 0.5878539352621649\n",
      "Epoch 550, Loss: 0.5866517462412044\n",
      "Epoch 560, Loss: 0.5854674976191567\n",
      "Epoch 570, Loss: 0.5843008329753493\n",
      "Epoch 580, Loss: 0.583151404203719\n",
      "Epoch 590, Loss: 0.5820188713121832\n",
      "Epoch 600, Loss: 0.5809029022259072\n",
      "Epoch 610, Loss: 0.5798031725944924\n",
      "Epoch 620, Loss: 0.5787193656031022\n",
      "Epoch 630, Loss: 0.5776511717875289\n",
      "Epoch 640, Loss: 0.5765982888531991\n",
      "Epoch 650, Loss: 0.5755604214981046\n",
      "Epoch 660, Loss: 0.5745372812396418\n",
      "Epoch 670, Loss: 0.5735285862453294\n",
      "Epoch 680, Loss: 0.5725340611673789\n",
      "Epoch 690, Loss: 0.5715534369810743\n",
      "Epoch 700, Loss: 0.5705864508269245\n",
      "Epoch 710, Loss: 0.5696328458565402\n",
      "Epoch 720, Loss: 0.5686923710821878\n",
      "Epoch 730, Loss: 0.5677647812299634\n",
      "Epoch 740, Loss: 0.5668498365965384\n",
      "Epoch 750, Loss: 0.5659473029094131\n",
      "Epoch 760, Loss: 0.5650569511906228\n",
      "Epoch 770, Loss: 0.5641785576238323\n",
      "Epoch 780, Loss: 0.563311903424759\n",
      "Epoch 790, Loss: 0.5624567747148594\n",
      "Epoch 800, Loss: 0.5616129623982143\n",
      "Epoch 810, Loss: 0.5607802620415488\n",
      "Epoch 820, Loss: 0.5599584737573226\n",
      "Epoch 830, Loss: 0.5591474020898223\n",
      "Epoch 840, Loss: 0.5583468559041926\n",
      "Epoch 850, Loss: 0.5575566482783406\n",
      "Epoch 860, Loss: 0.5567765963976468\n",
      "Epoch 870, Loss: 0.5560065214524198\n",
      "Epoch 880, Loss: 0.5552462485380303\n",
      "Epoch 890, Loss: 0.5544956065576578\n",
      "Epoch 900, Loss: 0.5537544281275929\n",
      "Epoch 910, Loss: 0.5530225494850269\n",
      "Epoch 920, Loss: 0.5522998103982711\n",
      "Epoch 930, Loss: 0.5515860540793451\n",
      "Epoch 940, Loss: 0.5508811270988727\n",
      "Epoch 950, Loss: 0.5501848793032282\n",
      "Epoch 960, Loss: 0.5494971637338767\n",
      "Epoch 970, Loss: 0.5488178365488487\n",
      "Epoch 980, Loss: 0.5481467569462972\n",
      "Epoch 990, Loss: 0.5474837870900805\n",
      "Epoch 0, Loss: 0.24878977683523273\n",
      "Epoch 10, Loss: 0.2472882648806589\n",
      "Epoch 20, Loss: 0.24581489233274165\n",
      "Epoch 30, Loss: 0.24436927315648663\n",
      "Epoch 40, Loss: 0.24295101151123405\n",
      "Epoch 50, Loss: 0.24155970298910995\n",
      "Epoch 60, Loss: 0.24019493580381804\n",
      "Epoch 70, Loss: 0.23885629192770416\n",
      "Epoch 80, Loss: 0.2375433481755429\n",
      "Epoch 90, Loss: 0.23625567723397586\n",
      "Epoch 100, Loss: 0.2349928486359782\n",
      "Epoch 110, Loss: 0.23375442968014112\n",
      "Epoch 120, Loss: 0.23253998629492714\n",
      "Epoch 130, Loss: 0.2313490838483937\n",
      "Epoch 140, Loss: 0.2301812879041726\n",
      "Epoch 150, Loss: 0.22903616492475737\n",
      "Epoch 160, Loss: 0.22791328292337196\n",
      "Epoch 170, Loss: 0.2268122120658883\n",
      "Epoch 180, Loss: 0.22573252522441667\n",
      "Epoch 190, Loss: 0.22467379848432428\n",
      "Epoch 200, Loss: 0.22363561160653847\n",
      "Epoch 210, Loss: 0.22261754844706613\n",
      "Epoch 220, Loss: 0.22161919733571675\n",
      "Epoch 230, Loss: 0.22064015141604523\n",
      "Epoch 240, Loss: 0.21968000894854786\n",
      "Epoch 250, Loss: 0.21873837357913944\n",
      "Epoch 260, Loss: 0.2178148545749237\n",
      "Epoch 270, Loss: 0.2169090670292395\n",
      "Epoch 280, Loss: 0.21602063203792463\n",
      "Epoch 290, Loss: 0.21514917684869017\n",
      "Epoch 300, Loss: 0.21429433498544234\n",
      "Epoch 310, Loss: 0.2134557463493261\n",
      "Epoch 320, Loss: 0.21263305729819698\n",
      "Epoch 330, Loss: 0.21182592070615958\n",
      "Epoch 340, Loss: 0.21103399600473588\n",
      "Epoch 350, Loss: 0.21025694920715315\n",
      "Epoch 360, Loss: 0.20949445291716734\n",
      "Epoch 370, Loss: 0.20874618632376085\n",
      "Epoch 380, Loss: 0.20801183518298053\n",
      "Epoch 390, Loss: 0.20729109178810853\n",
      "Epoch 400, Loss: 0.20658365492928596\n",
      "Epoch 410, Loss: 0.20588922984363955\n",
      "Epoch 420, Loss: 0.20520752815689533\n",
      "Epoch 430, Loss: 0.20453826781739495\n",
      "Epoch 440, Loss: 0.20388117302337025\n",
      "Epoch 450, Loss: 0.20323597414427\n",
      "Epoch 460, Loss: 0.20260240763687512\n",
      "Epoch 470, Loss: 0.20198021595688445\n",
      "Epoch 480, Loss: 0.20136914746660167\n",
      "Epoch 490, Loss: 0.2007689563393029\n",
      "Epoch 500, Loss: 0.2001794024608205\n",
      "Epoch 510, Loss: 0.19960025132883297\n",
      "Epoch 520, Loss: 0.19903127395031087\n",
      "Epoch 530, Loss: 0.1984722467375291\n",
      "Epoch 540, Loss: 0.19792295140302069\n",
      "Epoch 550, Loss: 0.19738317485381293\n",
      "Epoch 560, Loss: 0.19685270908525543\n",
      "Epoch 570, Loss: 0.1963313510747202\n",
      "Epoch 580, Loss: 0.19581890267542654\n",
      "Epoch 590, Loss: 0.19531517051061864\n",
      "Epoch 600, Loss: 0.19481996586829947\n",
      "Epoch 610, Loss: 0.19433310459670414\n",
      "Epoch 620, Loss: 0.19385440700067455\n",
      "Epoch 630, Loss: 0.19338369773907937\n",
      "Epoch 640, Loss: 0.1929208057234064\n",
      "Epoch 650, Loss: 0.19246556401763823\n",
      "Epoch 660, Loss: 0.1920178097395083\n",
      "Epoch 670, Loss: 0.19157738396322072\n",
      "Epoch 680, Loss: 0.19114413162370586\n",
      "Epoch 690, Loss: 0.1907179014224716\n",
      "Epoch 700, Loss: 0.19029854573510113\n",
      "Epoch 710, Loss: 0.18988592052043893\n",
      "Epoch 720, Loss: 0.18947988523149684\n",
      "Epoch 730, Loss: 0.1890803027281071\n",
      "Epoch 740, Loss: 0.18868703919133942\n",
      "Epoch 750, Loss: 0.18829996403969573\n",
      "Epoch 760, Loss: 0.18791894984708818\n",
      "Epoch 770, Loss: 0.18754387226260383\n",
      "Epoch 780, Loss: 0.1871746099320513\n",
      "Epoch 790, Loss: 0.1868110444212843\n",
      "Epoch 800, Loss: 0.18645306014129095\n",
      "Epoch 810, Loss: 0.18610054427503564\n",
      "Epoch 820, Loss: 0.18575338670603644\n",
      "Epoch 830, Loss: 0.18541147994866064\n",
      "Epoch 840, Loss: 0.1850747190801161\n",
      "Epoch 850, Loss: 0.18474300167411606\n",
      "Epoch 860, Loss: 0.18441622773619343\n",
      "Epoch 870, Loss: 0.1840942996406376\n",
      "Epoch 880, Loss: 0.1837771220690278\n",
      "Epoch 890, Loss: 0.18346460195033423\n",
      "Epoch 900, Loss: 0.18315664840255855\n",
      "Epoch 910, Loss: 0.18285317267588358\n",
      "Epoch 920, Loss: 0.1825540880973034\n",
      "Epoch 930, Loss: 0.18225931001670187\n",
      "Epoch 940, Loss: 0.1819687557543502\n",
      "Epoch 950, Loss: 0.18168234454979226\n",
      "Epoch 960, Loss: 0.1813999975120864\n",
      "Epoch 970, Loss: 0.18112163757137387\n",
      "Epoch 980, Loss: 0.1808471894317417\n",
      "Epoch 990, Loss: 0.18057657952535128\n",
      "Accuracy with BCE Loss (Sigmoid): 0.45\n",
      "Accuracy with MSE Loss (Sigmoid): 0.47\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# # import wandb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# class MLPBinaryClassifier:\n",
    "#     def __init__(self, input_size, learning_rate=0.01, loss_type='bce', epochs=100):\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.loss_type = loss_type\n",
    "#         self.epochs = epochs\n",
    "#         self.weights = np.random.randn(input_size, 1) * 0.01\n",
    "#         self.bias = np.zeros((1, 1))\n",
    "#         self.losses = []\n",
    "\n",
    "#     def sigmoid(self, z):\n",
    "#         return 1 / (1 + np.exp(-z))\n",
    "\n",
    "#     def forward(self, X):\n",
    "#         z = np.dot(X, self.weights) + self.bias\n",
    "#         return self.sigmoid(z)\n",
    "\n",
    "#     def compute_loss(self, A, y):\n",
    "#         m = y.shape[0]\n",
    "#         if self.loss_type == 'bce':\n",
    "#             loss = -1/m * (np.dot(y.T, np.log(A)) + np.dot((1 - y).T, np.log(1 - A)))\n",
    "#         elif self.loss_type == 'mse':\n",
    "#             loss = np.mean((A - y) ** 2)\n",
    "#         return loss.item()  # Return as scalar\n",
    "\n",
    "#     def backprop(self, X, A, y):\n",
    "#         m = y.shape[0]\n",
    "#         dz = A - y\n",
    "#         dw = (1/m) * np.dot(X.T, dz)\n",
    "#         db = (1/m) * np.sum(dz)\n",
    "#         return dw, db\n",
    "\n",
    "#     def update_weights(self, dw, db):\n",
    "#         self.weights -= self.learning_rate * dw\n",
    "#         self.bias -= self.learning_rate * db\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         y = y.reshape(-1, 1)\n",
    "#         for epoch in range(self.epochs):\n",
    "#             A = self.forward(X)\n",
    "#             loss = self.compute_loss(A, y)\n",
    "#             self.losses.append(loss)\n",
    "#             dw, db = self.backprop(X, A, y)\n",
    "#             self.update_weights(dw, db)\n",
    "\n",
    "#             if epoch % 10 == 0:\n",
    "#                 print(f'Epoch {epoch}, Loss: {loss}')\n",
    "#                 # wandb.log({\"loss\": loss})  # Log to WandB\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         A = self.forward(X)\n",
    "#         return (A > 0.5).astype(int)\n",
    "\n",
    "# # # # Initialize WandB\n",
    "# # wandb.init(project='diabetes-classification', entity='your_entity_name')\n",
    "\n",
    "# # Train models\n",
    "# model_bce = MLPBinaryClassifier(input_size=X_train.shape[1], learning_rate=0.01, loss_type='bce', epochs=200)\n",
    "# model_bce.fit(X_train, y_train)\n",
    "\n",
    "# model_mse = MLPBinaryClassifier(input_size=X_train.shape[1], learning_rate=0.01, loss_type='mse', epochs=200)\n",
    "# model_mse.fit(X_train, y_train)\n",
    "\n",
    "# # Predict and evaluate\n",
    "# y_pred_bce = model_bce.predict(X_test)\n",
    "# y_pred_mse = model_mse.predict(X_test)\n",
    "\n",
    "# accuracy_bce = np.mean(y_pred_bce.flatten() == y_test)\n",
    "# accuracy_mse = np.mean(y_pred_mse.flatten() == y_test)\n",
    "\n",
    "# print(f'Accuracy with BCE Loss: {accuracy_bce:.2f}')\n",
    "# print(f'Accuracy with MSE Loss: {accuracy_mse:.2f}')\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(model_bce.losses, label='BCE Loss')\n",
    "# plt.title('BCE Loss vs Epochs')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(model_mse.losses, label='MSE Loss', color='red')\n",
    "# plt.title('MSE Loss vs Epochs')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "X = data.iloc[:, :-1].values  # All columns except the last\n",
    "y = data.iloc[:, -1].values   # Last column\n",
    "\n",
    "\n",
    "X_train, X_testval, y_train, y_testval = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_testval, y_testval, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "class MLPBinary:\n",
    "    def __init__(self, input_size, learning_rate=0.01, loss_type='bce', epochs=100, activation='sigmoid'):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss_type = loss_type\n",
    "        self.epochs = epochs\n",
    "        self.activation = activation\n",
    "        self.weights = np.random.randn(input_size, 1) * 0.01\n",
    "        self.bias = np.zeros((1, 1))\n",
    "        self.losses = []\n",
    "\n",
    "    # Activation functions\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def relu(self, z):\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    def tanh(self, z):\n",
    "        return np.tanh(z)\n",
    "\n",
    "    # Derivatives for activation functions (needed for backprop)\n",
    "    def sigmoid_derivative(self, z):\n",
    "        return self.sigmoid(z) * (1 - self.sigmoid(z))\n",
    "\n",
    "    def relu_derivative(self, z):\n",
    "        return np.where(z > 0, 1, 0)\n",
    "\n",
    "    def tanh_derivative(self, z):\n",
    "        return 1 - np.tanh(z) ** 2\n",
    "\n",
    "    # Forward pass based on selected activation function\n",
    "    def forward(self, X):\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        if self.activation == 'sigmoid':\n",
    "            return self.sigmoid(z)\n",
    "        elif self.activation == 'relu':\n",
    "            return self.relu(z)\n",
    "        elif self.activation == 'tanh':\n",
    "            return self.tanh(z)\n",
    "\n",
    "    def compute_loss(self, A, y):\n",
    "        m = y.shape[0]\n",
    "        if self.loss_type == 'bce':\n",
    "            loss = -np.mean(y * np.log(A) + (1 - y) * np.log(1 - A))\n",
    "        elif self.loss_type == 'mse':\n",
    "            loss = np.mean((A - y) ** 2)\n",
    "        return loss\n",
    "\n",
    "    def backprop(self, X, A, y):\n",
    "        m = y.shape[0]\n",
    "        dz = A - y  # Derivative of loss w.r.t activation output\n",
    "\n",
    "        # Derivative of activation function\n",
    "        if self.activation == 'sigmoid':\n",
    "            dz *= self.sigmoid_derivative(A)\n",
    "        elif self.activation == 'relu':\n",
    "            dz *= self.relu_derivative(A)\n",
    "        elif self.activation == 'tanh':\n",
    "            dz *= self.tanh_derivative(A)\n",
    "\n",
    "        dw = (1/m) * np.dot(X.T, dz)\n",
    "        db = (1/m) * np.sum(dz)\n",
    "        return dw, db\n",
    "\n",
    "    def update_weights(self, dw, db):\n",
    "        self.weights -= self.learning_rate * dw\n",
    "        self.bias -= self.learning_rate * db\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = y.reshape(-1, 1)\n",
    "        for epoch in range(self.epochs):\n",
    "            A = self.forward(X)\n",
    "            loss = self.compute_loss(A, y)\n",
    "            self.losses.append(loss)\n",
    "            dw, db = self.backprop(X, A, y)\n",
    "            self.update_weights(dw, db)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        A = self.forward(X)\n",
    "        return (A > 0.5).astype(int)\n",
    "\n",
    "\n",
    "# Now, you can test with different activation functions\n",
    "\n",
    "# Model with BCE loss and sigmoid activation\n",
    "model_bce_sigmoid = MLPBinary(input_size=X_train.shape[1], learning_rate=0.01, loss_type='bce', epochs=1000, activation='sigmoid')\n",
    "model_bce_sigmoid.fit(X_train, y_train)\n",
    "\n",
    "# Model with MSE loss and relu activation\n",
    "model_mse_relu = MLPBinary(input_size=X_train.shape[1], learning_rate=0.01, loss_type='mse', epochs=1000, activation='sigmoid')\n",
    "model_mse_relu.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_bce_sigmoid = model_bce_sigmoid.predict(X_test)\n",
    "y_pred_mse_relu = model_mse_relu.predict(X_test)\n",
    "\n",
    "accuracy_bce_sigmoid = np.mean(y_pred_bce_sigmoid.flatten() == y_test)\n",
    "accuracy_mse_relu = np.mean(y_pred_mse_relu.flatten() == y_test)\n",
    "\n",
    "print(f'Accuracy with BCE Loss (Sigmoid): {accuracy_bce_sigmoid:.2f}')\n",
    "print(f'Accuracy with MSE Loss (Sigmoid): {accuracy_mse_relu:.2f}')\n",
    "\n",
    "# Plotting the losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(model_bce_sigmoid.losses, label='BCE Loss (Sigmoid)')\n",
    "plt.title('BCE Loss with Sigmoid Activation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(model_mse_relu.losses, label='MSE Loss (ReLU)', color='red')\n",
    "plt.title('MSE Loss with ReLU Activation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "### AutoEncoders\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (91200, 13)\n",
      "y_train shape: (91200,)\n",
      "X_validate shape: (11400, 13)\n",
      "y_validate shape: (11400,)\n",
      "X_test shape: (11400, 13)\n",
      "y_test shape: (11400,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Load the Dataset\n",
    "data = pd.read_csv('../../data/external/spotify.csv')\n",
    "\n",
    "# Step 3: Select Numeric Columns (6 to 20, excluding column 8)\n",
    "numeric_data = data.iloc[:, [6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Step 4: Remove Invalid Values\n",
    "numeric_data = numeric_data.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "# Step 5: Split into Input and Output\n",
    "output_column = data.iloc[numeric_data.index, -1]  # Assuming the output column is now the last one\n",
    "X = numeric_data  # Input features with the output column removed\n",
    "y = output_column.reset_index(drop=True)  # Output labels\n",
    "\n",
    "# Step 7: Standardize Remaining Data\n",
    "scaler = MinMaxScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "# Step 8: Split the Data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_standardized, y, test_size=0.2, random_state=42)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Output the shapes of the resulting datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_validate shape:\", X_validate.shape)\n",
    "print(\"y_validate shape:\", y_validate.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class AutoEncoder:\n",
    "    def __init__(self, input_size, hidden_size, activation='relu', optimizer='sgd', learning_rate=0.01, batch_size=32, epochs=100):\n",
    "        # Initialize weights and biases for encoder and decoder\n",
    "        self.encoder_weights = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.encoder_bias = np.zeros((1, hidden_size))\n",
    "        self.decoder_weights = np.random.randn(hidden_size, input_size) * 0.01\n",
    "        self.decoder_bias = np.zeros((1, input_size))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation = self.get_activation_func(activation)\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def get_activation_func(self, name):\n",
    "        if name == 'sigmoid':\n",
    "            return lambda x: 1 / (1 + np.exp(-x)), lambda x: x * (1 - x)  # Sigmoid and its derivative\n",
    "        elif name == 'tanh':\n",
    "            return lambda x: np.tanh(x), lambda x: 1 - x ** 2  # Tanh and its derivative\n",
    "        elif name == 'relu':\n",
    "            return lambda x: np.maximum(0, x), lambda x: np.where(x > 0, 1, 0)  # ReLU and its derivative\n",
    "        elif name == 'linear':\n",
    "            return lambda x: x, lambda x: 1  # Linear activation (for reconstruction)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Encoder forward pass\n",
    "        self.z1 = np.dot(X, self.encoder_weights) + self.encoder_bias\n",
    "        self.a1 = self.activation[0](self.z1)\n",
    "        \n",
    "        # Decoder forward pass (reconstruction)\n",
    "        self.z2 = np.dot(self.a1, self.decoder_weights) + self.decoder_bias\n",
    "        self.a2 = self.activation[0](self.z2)\n",
    "        \n",
    "        return self.a2\n",
    "\n",
    "    def backprop(self, X, reconstruction):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Compute reconstruction error\n",
    "        dz2 = (reconstruction - X) * self.activation[1](reconstruction)\n",
    "        dw2 = np.dot(self.a1.T, dz2) / m\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "        \n",
    "        dz1 = np.dot(dz2, self.decoder_weights.T) * self.activation[1](self.a1)\n",
    "        dw1 = np.dot(X.T, dz1) / m\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "        \n",
    "        return dw1, db1, dw2, db2\n",
    "\n",
    "    def update_weights(self, dw1, db1, dw2, db2):\n",
    "        self.encoder_weights -= self.learning_rate * dw1\n",
    "        self.encoder_bias -= self.learning_rate * db1\n",
    "        self.decoder_weights -= self.learning_rate * dw2\n",
    "        self.decoder_bias -= self.learning_rate * db2\n",
    "\n",
    "    def fit_sgd(self, X):\n",
    "        # Training using Stochastic Gradient Descent (SGD)\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                # Forward pass\n",
    "                x_single = X[i:i+1]  # Single example\n",
    "                reconstruction = self.forward(x_single)\n",
    "                \n",
    "                # Backpropagation\n",
    "                dw1, db1, dw2, db2 = self.backprop(x_single, reconstruction)\n",
    "                \n",
    "                # Update weights\n",
    "                self.update_weights(dw1, db1, dw2, db2)\n",
    "\n",
    "    def fit_batch(self, X):\n",
    "        # Training using Batch Gradient Descent\n",
    "        for epoch in range(self.epochs):\n",
    "            reconstruction = self.forward(X)\n",
    "            dw1, db1, dw2, db2 = self.backprop(X, reconstruction)\n",
    "            self.update_weights(dw1, db1, dw2, db2)\n",
    "\n",
    "    def fit_mini_batch(self, X):\n",
    "        # Training using Mini-Batch Gradient Descent\n",
    "        for epoch in range(self.epochs):\n",
    "            for start_idx in range(0, X.shape[0], self.batch_size):\n",
    "                end_idx = start_idx + self.batch_size\n",
    "                X_batch = X[start_idx:end_idx]\n",
    "                \n",
    "                # Forward pass\n",
    "                reconstruction = self.forward(X_batch)\n",
    "                \n",
    "                # Backpropagation\n",
    "                dw1, db1, dw2, db2 = self.backprop(X_batch, reconstruction)\n",
    "                \n",
    "                # Update weights\n",
    "                self.update_weights(dw1, db1, dw2, db2)\n",
    "\n",
    "    def fit(self, X):\n",
    "        if self.optimizer == 'sgd':\n",
    "            self.fit_sgd(X)\n",
    "        elif self.optimizer == 'batch':\n",
    "            self.fit_batch(X)\n",
    "        elif self.optimizer == 'mini_batch':\n",
    "            self.fit_mini_batch(X)\n",
    "\n",
    "    def get_latent(self, X):\n",
    "        # Return the encoded (compressed) data\n",
    "        return self.activation[0](np.dot(X, self.encoder_weights) + self.encoder_bias)\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        # Perform a forward pass to reconstruct the data\n",
    "        return self.forward(X)\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "input_size = X_train.shape[1]  # Number of input features\n",
    "hidden_size = 8  # Latent space size\n",
    "\n",
    "# Initialize the autoencoder with ReLU activation and Mini-Batch Gradient Descent\n",
    "autoencoder = AutoEncoder(input_size, hidden_size, activation='relu', optimizer='batch', learning_rate=0.01, batch_size=32, epochs=100)\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train)\n",
    "\n",
    "# Obtain the reduced (latent) dataset\n",
    "latent_train = autoencoder.get_latent(X_train)\n",
    "latent_test = autoencoder.get_latent(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to DataFrame, shape must be (91200, 13): given (91200, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1852\\4161744396.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;31m# Initialize the autoencoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[0mautoencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mini_batch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;31m# Train the autoencoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;31m# Get the reduced (latent) representations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[0mlatent_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_latent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1852\\4161744396.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mreconstruction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[1;31m# Backpropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[0mdws_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbs_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdws_decoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbs_decoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreconstruction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m             \u001b[1;31m# Update weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdws_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbs_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdws_decoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbs_decoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1852\\4161744396.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, reconstruction)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreconstruction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;31m# Encoder backpropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mdws_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbs_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;31m# Decoder backpropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mdws_decoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbs_decoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreconstruction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdws_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbs_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdws_decoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbs_decoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1852\\4161744396.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, output)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Number of examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mdz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Shape: (m, output_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mdws\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mdbs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2167\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2168\u001b[0m     def __array_ufunc__(\n\u001b[0;32m   2169\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2170\u001b[0m     \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2171\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_ufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_standardize_out_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;31m# for binary ops, use our custom dunder methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_dispatch_ufunc_to_dunder_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mops_dispatch.pyx\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m \u001b[1;34m'Could not get source, probably due dynamically evaluated source code.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__rsub__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7907\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# only relevant for Series other case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7908\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_prepare_scalar_for_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7910\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_align_for_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7912\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7913\u001b[0m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch_frame_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, other, axis, flex, level)\u001b[0m\n\u001b[0;32m   8165\u001b[0m                     \u001b[1;31m# Broadcast along rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8166\u001b[0m                     \u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8168\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8169\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m   8170\u001b[0m                         \u001b[1;34m\"Unable to coerce to DataFrame, shape \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8171\u001b[0m                         \u001b[1;33mf\"\u001b[0m\u001b[1;33mmust be \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m: given \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8172\u001b[0m                     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to coerce to DataFrame, shape must be (91200, 13): given (91200, 8)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLPRegression:\n",
    "    def __init__(self, layer_sizes, activation='relu', learning_rate=0.01):\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.weights.append(np.random.randn(layer_sizes[i], layer_sizes[i + 1]) * 0.01)\n",
    "            self.biases.append(np.zeros((1, layer_sizes[i + 1])))\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation = self.get_activation_func(activation)\n",
    "\n",
    "    def get_activation_func(self, name):\n",
    "        if name == 'sigmoid':\n",
    "            return (lambda x: 1 / (1 + np.exp(-x)), lambda x: x * (1 - x))  # Sigmoid and its derivative\n",
    "        elif name == 'tanh':\n",
    "            return (lambda x: np.tanh(x), lambda x: 1 - x ** 2)  # Tanh and its derivative\n",
    "        elif name == 'relu':\n",
    "            return (lambda x: np.maximum(0, x), lambda x: np.where(x > 0, 1, 0))  # ReLU and its derivative\n",
    "        elif name == 'linear':\n",
    "            return (lambda x: x, lambda x: 1)  # Linear activation (for reconstruction)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.a = X\n",
    "        self.zs = []  # Store z values for backpropagation\n",
    "        for weight, bias in zip(self.weights, self.biases):\n",
    "            z = np.dot(self.a, weight) + bias\n",
    "            self.zs.append(z)\n",
    "            self.a = self.activation[0](z)  # Apply activation function\n",
    "        return self.a\n",
    "\n",
    "    def backprop(self, X, output):\n",
    "        m = X.shape[0]  # Number of examples\n",
    "        dz = (output - X) * self.activation[1](output)  # Shape: (m, output_size)\n",
    "\n",
    "        dws = []\n",
    "        dbs = []\n",
    "\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            dw = np.dot(self.a.T, dz) / m  # Shape: (previous_layer_size, output_size)\n",
    "            db = np.sum(dz, axis=0, keepdims=True) / m  # Shape: (1, output_size)\n",
    "            dws.append(dw)\n",
    "            dbs.append(db)\n",
    "\n",
    "            if i > 0:  # Don't backpropagate through the input layer\n",
    "                dz = np.dot(dz, self.weights[i].T) * self.activation[1](self.zs[i - 1])  # Shape: (m, hidden_size)\n",
    "\n",
    "        return list(reversed(dws)), list(reversed(dbs))\n",
    "\n",
    "    def update_weights(self, dws, dbs):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * dws[i]\n",
    "            self.biases[i] -= self.learning_rate * dbs[i]\n",
    "\n",
    "    def fit(self, X, optimizer='sgd', batch_size=32, epochs=100):\n",
    "        if optimizer == 'sgd':\n",
    "            self.fit_sgd(X, epochs)\n",
    "        elif optimizer == 'batch':\n",
    "            self.fit_batch(X, epochs)\n",
    "        elif optimizer == 'mini_batch':\n",
    "            self.fit_mini_batch(X, batch_size, epochs)\n",
    "\n",
    "    def fit_sgd(self, X, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                x_single = X[i:i + 1]  # Shape: (1, input_size)\n",
    "                output = self.forward(x_single)\n",
    "                dws, dbs = self.backprop(x_single, output)\n",
    "                self.update_weights(dws, dbs)\n",
    "\n",
    "    def fit_batch(self, X, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            dws, dbs = self.backprop(X, output)\n",
    "            self.update_weights(dws, dbs)\n",
    "\n",
    "    def fit_mini_batch(self, X, batch_size, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for start_idx in range(0, X.shape[0], batch_size):\n",
    "                end_idx = start_idx + batch_size\n",
    "                X_batch = X[start_idx:end_idx]  # Shape: (batch_size, input_size)\n",
    "                output = self.forward(X_batch)\n",
    "                dws, dbs = self.backprop(X_batch, output)\n",
    "                self.update_weights(dws, dbs)\n",
    "\n",
    "class AutoEncoder:\n",
    "    def __init__(self, input_size, hidden_layers, activation='relu', learning_rate=0.01, optimizer='sgd', epochs=100, batch_size=32):\n",
    "        # Hidden layers for encoder\n",
    "        self.encoder = MLPRegression([input_size] + hidden_layers, activation, learning_rate)\n",
    "        # Hidden layers for decoder, mirroring the encoder structure\n",
    "        self.decoder = MLPRegression(list(reversed(hidden_layers)) + [input_size], activation, learning_rate)  # Output size matches input size\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, X):\n",
    "        encoded = self.encoder.forward(X)  # Shape: (m, last_hidden_size)\n",
    "        reconstructed = self.decoder.forward(encoded)  # Shape: (m, input_size)\n",
    "        return reconstructed\n",
    "\n",
    "    def backprop(self, X, reconstruction):\n",
    "        # Encoder backpropagation\n",
    "        dws_encoder, dbs_encoder = self.encoder.backprop(X, self.encoder.a)\n",
    "        # Decoder backpropagation\n",
    "        dws_decoder, dbs_decoder = self.decoder.backprop(self.encoder.a, reconstruction)\n",
    "        return dws_encoder, dbs_encoder, dws_decoder, dbs_decoder\n",
    "\n",
    "    def update_weights(self, dws_encoder, dbs_encoder, dws_decoder, dbs_decoder):\n",
    "        self.encoder.update_weights(dws_encoder, dbs_encoder)\n",
    "        self.decoder.update_weights(dws_decoder, dbs_decoder)\n",
    "\n",
    "    def fit(self, X):\n",
    "        for epoch in range(self.epochs):\n",
    "            # Forward pass\n",
    "            reconstruction = self.forward(X)\n",
    "            # Backpropagation\n",
    "            dws_encoder, dbs_encoder, dws_decoder, dbs_decoder = self.backprop(X, reconstruction)\n",
    "            # Update weights\n",
    "            self.update_weights(dws_encoder, dbs_encoder, dws_decoder, dbs_decoder)\n",
    "\n",
    "    def get_latent(self, X):\n",
    "        return self.encoder.forward(X)  # Shape: (m, last_hidden_size)\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        return self.forward(X)  # Shape: (m, input_size)\n",
    "    \n",
    "# Example usage:\n",
    "# Assuming X_train and X_test are your training and testing datasets\n",
    "input_size = X_train.shape[1]  # Number of features in your dataset\n",
    "hidden_layers = [8]  # Size of the hidden layer\n",
    "# Initialize the autoencoder\n",
    "autoencoder = AutoEncoder(input_size, hidden_layers, activation='relu', learning_rate=0.01, optimizer='mini_batch', epochs=100, batch_size=32)\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train)\n",
    "\n",
    "# Get the reduced (latent) representations\n",
    "latent_train = autoencoder.get_latent(X_train)\n",
    "latent_test = autoencoder.get_latent(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, layers, learning_rate=0.01, activation='relu', optimizer='sgd', batch_size=32, epochs=100):\n",
    "        self.layers = layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation_func = self.get_activation_func(activation)\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.weights, self.biases = self.initialize_weights()\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        np.random.seed(42)\n",
    "        weights = []\n",
    "        biases = []\n",
    "        for i in range(1, len(self.layers)):\n",
    "            weights.append(np.random.randn(self.layers[i], self.layers[i - 1]) * 0.01)\n",
    "            biases.append(np.zeros((self.layers[i], 1)))\n",
    "        return weights, biases\n",
    "\n",
    "    def get_activation_func(self, name):\n",
    "        if name == 'sigmoid':\n",
    "            return lambda x: 1 / (1 + np.exp(-np.clip(x, -500, 500))), lambda x: x * (1 - x)\n",
    "        elif name == 'tanh':\n",
    "            return lambda x: np.tanh(x), lambda x: 1 - x ** 2\n",
    "        elif name == 'relu':\n",
    "            return lambda x: np.maximum(0, x), lambda x: np.where(x > 0, 1, 0)\n",
    "        else:  # linear\n",
    "            return lambda x: x, lambda x: 1\n",
    "\n",
    "    def forward(self, X):\n",
    "        a = X.T\n",
    "        activations = [a]\n",
    "        z_values = []\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w, a) + b\n",
    "            a = self.activation_func[0](z)\n",
    "            z_values.append(z)\n",
    "            activations.append(a)\n",
    "        return activations, z_values\n",
    "\n",
    "    def backward(self, X, y, activations, z_values):\n",
    "        m = y.shape[0]\n",
    "        dz = activations[-1] - y.T\n",
    "        dws = []\n",
    "        dbs = []\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            dw = (1/m) * np.dot(dz, activations[i].T)\n",
    "            db = (1/m) * np.sum(dz, axis=1, keepdims=True)\n",
    "            np.clip(dw, -1e5, 1e5, out=dw)\n",
    "            np.clip(db, -1e5, 1e5, out=db)\n",
    "            dws.insert(0, dw)\n",
    "            dbs.insert(0, db)\n",
    "            if i > 0:\n",
    "                dz = np.dot(self.weights[i].T, dz) * self.activation_func[1](z_values[i-1])\n",
    "        return dws, dbs\n",
    "\n",
    "    def update_weights(self, dws, dbs):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * dws[i]\n",
    "            self.biases[i] -= self.learning_rate * dbs[i]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.optimizer == 'sgd':\n",
    "            self.fit_sgd(X, y)\n",
    "        elif self.optimizer == 'mini_batch':\n",
    "            self.fit_mini_batch(X, y)\n",
    "        elif self.optimizer == 'batch':\n",
    "            self.fit_batch(X, y)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported optimizer. Choose 'sgd', 'mini_batch', or 'batch'.\")\n",
    "\n",
    "    def fit_sgd(self, X, y):\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(len(X)):\n",
    "                Xi = X[i:i+1]\n",
    "                yi = y[i:i+1]\n",
    "                activations, z_values = self.forward(Xi)\n",
    "                dws, dbs = self.backward(Xi, yi, activations, z_values)\n",
    "                self.update_weights(dws, dbs)\n",
    "\n",
    "    def fit_mini_batch(self, X, y):\n",
    "        for epoch in range(self.epochs):\n",
    "            for start_idx in range(0, len(X), self.batch_size):\n",
    "                end_idx = start_idx + self.batch_size\n",
    "                X_batch = X[start_idx:end_idx]\n",
    "                y_batch = y[start_idx:end_idx]\n",
    "                activations, z_values = self.forward(X_batch)\n",
    "                dws, dbs = self.backward(X_batch, y_batch, activations, z_values)\n",
    "                self.update_weights(dws, dbs)\n",
    "\n",
    "    def fit_batch(self, X, y):\n",
    "        for epoch in range(self.epochs):\n",
    "            activations, z_values = self.forward(X)\n",
    "            dws, dbs = self.backward(X, y, activations, z_values)\n",
    "            self.update_weights(dws, dbs)\n",
    "\n",
    "    def predict(self, X):\n",
    "        activations, _ = self.forward(X)\n",
    "        return activations[-1].T\n",
    "\n",
    "class AutoEncoder:\n",
    "    def __init__(self, input_dim, latent_dim, hidden_layers=(64, 32), learning_rate=0.01, activation='relu', optimizer='mini_batch', batch_size=32, epochs=100):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        # Encoder\n",
    "        encoder_layers = [input_dim] + list(hidden_layers) + [latent_dim]\n",
    "        self.encoder = MLP(encoder_layers, learning_rate, activation, optimizer, batch_size, epochs)\n",
    "        \n",
    "        # Decoder\n",
    "        decoder_layers = [latent_dim] + list(reversed(hidden_layers)) + [input_dim]\n",
    "        self.decoder = MLP(decoder_layers, learning_rate, activation, optimizer, batch_size, epochs)\n",
    "    \n",
    "    def fit(self, X):\n",
    "        if self.optimizer == 'sgd':\n",
    "            self.fit_sgd(X)\n",
    "        elif self.optimizer == 'mini_batch':\n",
    "            self.fit_mini_batch(X)\n",
    "        elif self.optimizer == 'batch':\n",
    "            self.fit_batch(X)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported optimizer. Choose 'sgd', 'mini_batch', or 'batch'.\")\n",
    "\n",
    "    def fit_sgd(self, X):\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(len(X)):\n",
    "                Xi = X[i:i+1]\n",
    "                encoded = self.encoder.predict(Xi)\n",
    "                self.encoder.fit_sgd(Xi, encoded)\n",
    "                self.decoder.fit_sgd(encoded, Xi)\n",
    "\n",
    "    def fit_mini_batch(self, X):\n",
    "        for epoch in range(self.epochs):\n",
    "            for start_idx in range(0, len(X), self.batch_size):\n",
    "                end_idx = start_idx + self.batch_size\n",
    "                batch = X[start_idx:end_idx]\n",
    "                encoded = self.encoder.predict(batch)\n",
    "                self.encoder.fit_mini_batch(batch, encoded)\n",
    "                self.decoder.fit_mini_batch(encoded, batch)\n",
    "\n",
    "    def fit_batch(self, X):\n",
    "        for epoch in range(self.epochs):\n",
    "            encoded = self.encoder.predict(X)\n",
    "            self.encoder.fit_batch(X, encoded)\n",
    "            self.decoder.fit_batch(encoded, X)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            mse = np.mean((X - self.predict(X)) ** 2)\n",
    "            print(f\"Epoch {epoch}, MSE: {mse}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        encoded = self.get_latent(X)\n",
    "        return self.decoder.predict(encoded)\n",
    "    \n",
    "    def get_latent(self, X):\n",
    "        return self.encoder.predict(X)\n",
    "\n",
    "\n",
    "# Example usage for AutoEncoder with ReLU and Mini-Batch Gradient Descent\n",
    "input_size = X_train.shape[1]  # Number of input features\n",
    "hidden_size = 11  # Size of the latent space\n",
    "\n",
    "# Initialize AutoEncoder with ReLU activation and Mini-Batch Gradient Descent\n",
    "autoencoder = AutoEncoder(input_size, hidden_size, activation='relu', optimizer='mini_batch', learning_rate=0.01, batch_size=32, epochs=10)\n",
    "\n",
    "# Train the AutoEncoder\n",
    "autoencoder.fit(X_train)\n",
    "\n",
    "# Get the latent representation (encoded data)\n",
    "latent_train = autoencoder.get_latent(X_train)\n",
    "latent_test = autoencoder.get_latent(X_test)\n",
    "\n",
    "# Reconstruct the data\n",
    "# reconstructed_data = autoencoder.reconstruct(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.13892316992686599\n",
      "Epoch 2, Loss: 0.0639927393131553\n",
      "Epoch 3, Loss: 0.06385097404972702\n",
      "Epoch 4, Loss: 0.0637097550590994\n",
      "Epoch 5, Loss: 0.06356908265238864\n",
      "Epoch 6, Loss: 0.06342895706493293\n",
      "Epoch 7, Loss: 0.06328937845748775\n",
      "Epoch 8, Loss: 0.06315034691743075\n",
      "Epoch 9, Loss: 0.06301186245997478\n",
      "Epoch 10, Loss: 0.06287392502938799\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, layers, activation='relu', learning_rate=0.01, optimizer='sgd', batch_size=32, epochs=100):\n",
    "        self.layers = layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation_func = self.get_activation_func(activation)\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.weights, self.biases = self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        np.random.seed(42)\n",
    "        weights = []\n",
    "        biases = []\n",
    "        for i in range(1, len(self.layers)):\n",
    "            weights.append(np.random.randn(self.layers[i], self.layers[i - 1]) * 0.01)\n",
    "            biases.append(np.zeros((self.layers[i], 1)))\n",
    "        return weights, biases\n",
    "\n",
    "    def get_activation_func(self, name):\n",
    "        if name == 'sigmoid':\n",
    "            return lambda x: 1 / (1 + np.exp(-x)), lambda x: x * (1 - x)\n",
    "        elif name == 'tanh':\n",
    "            return lambda x: np.tanh(x), lambda x: 1 - x ** 2\n",
    "        elif name == 'relu':\n",
    "            return lambda x: np.maximum(0, x), lambda x: np.where(x > 0, 1, 0)\n",
    "        elif name == 'linear':\n",
    "            return lambda x: x, lambda x: 1\n",
    "\n",
    "    def forward(self, X):\n",
    "        a = X.T\n",
    "        activations = [a]\n",
    "        z_values = []\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w, a) + b\n",
    "            a = self.activation_func[0](z)\n",
    "            z_values.append(z)\n",
    "            activations.append(a)\n",
    "        return activations, z_values\n",
    "\n",
    "    def backprop(self, activations, z_values, y):\n",
    "        m = y.shape[0]\n",
    "        dz = activations[-1] - y\n",
    "        dws = []\n",
    "        dbs = []\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            dw = (1/m) * np.dot(dz, activations[i].T)\n",
    "            db = (1/m) * np.sum(dz, axis=1, keepdims=True)\n",
    "            dws.insert(0, dw)\n",
    "            dbs.insert(0, db)\n",
    "            if i > 0:\n",
    "                dz = np.dot(self.weights[i].T, dz) * self.activation_func[1](z_values[i-1])\n",
    "        return dws, dbs\n",
    "\n",
    "    def update_weights(self, dws, dbs):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * dws[i]\n",
    "            self.biases[i] -= self.learning_rate * dbs[i]\n",
    "\n",
    "    def fit_sgd(self, X_train, y_train):\n",
    "        y_train = y_train.T\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(X_train.shape[0]):\n",
    "                X_sample = X_train[i:i+1]\n",
    "                y_sample = y_train[:, i:i+1]\n",
    "                activations, z_values = self.forward(X_sample)\n",
    "                dws, dbs = self.backprop(activations, z_values, y_sample)\n",
    "                self.update_weights(dws, dbs)\n",
    "\n",
    "    def fit_batch(self, X_train, y_train):\n",
    "        y_train = y_train.T\n",
    "        for epoch in range(self.epochs):\n",
    "            activations, z_values = self.forward(X_train)\n",
    "            dws, dbs = self.backprop(activations, z_values, y_train)\n",
    "            self.update_weights(dws, dbs)\n",
    "\n",
    "    def fit_mini_batch(self, X_train, y_train):\n",
    "        y_train = y_train.T\n",
    "        for epoch in range(self.epochs):\n",
    "            for start_idx in range(0, X_train.shape[0], self.batch_size):\n",
    "                end_idx = start_idx + self.batch_size\n",
    "                X_batch = X_train[start_idx:end_idx]\n",
    "                y_batch = y_train[:, start_idx:end_idx]\n",
    "                activations, z_values = self.forward(X_batch)\n",
    "                dws, dbs = self.backprop(activations, z_values, y_batch)\n",
    "                self.update_weights(dws, dbs)\n",
    "\n",
    "            # Calculate and print loss for the epoch\n",
    "            # loss = np.mean((self.predict(X_train) - y_train) ** 2)\n",
    "            # print(f'Epoch {epoch + 1}, Loss: {loss}')\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        if self.optimizer == 'sgd':\n",
    "            self.fit_sgd(X_train, y_train)\n",
    "        elif self.optimizer == 'batch':\n",
    "            self.fit_batch(X_train, y_train)\n",
    "        elif self.optimizer == 'mini_batch':\n",
    "            self.fit_mini_batch(X_train, y_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        activations, _ = self.forward(X)\n",
    "        return activations[-1].T\n",
    "\n",
    "\n",
    "class AutoEncoder:\n",
    "    def __init__(self, input_size, hidden_layers, latent_size, activation='relu', optimizer='sgd', learning_rate=0.01, batch_size=32, epochs=100):\n",
    "        \"\"\"\n",
    "        AutoEncoder: Encoder + Decoder.\n",
    "        - input_size: The size of the input layer.\n",
    "        - hidden_layers: List of sizes for encoder hidden layers.\n",
    "        - latent_size: Size of the latent (compressed) space.\n",
    "        \"\"\"\n",
    "        # Define encoder structure: input_size -> hidden_layers -> latent_size\n",
    "        encoder_layers = [input_size] + hidden_layers + [latent_size]\n",
    "        self.encoder = MLP(encoder_layers, activation, learning_rate, optimizer, batch_size, epochs)\n",
    "\n",
    "        # Define decoder structure: latent_size -> reversed(hidden_layers) -> input_size\n",
    "        decoder_layers = [latent_size] + hidden_layers[::-1] + [input_size]\n",
    "        self.decoder = MLP(decoder_layers, activation, learning_rate, optimizer, batch_size, epochs)\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Train the AutoEncoder.\n",
    "        \"\"\"\n",
    "        X = np.array(X, dtype=float)\n",
    "        assert X.ndim == 2, \"Input X must be a 2D array (batch_size, input_size).\"\n",
    "\n",
    "        for epoch in range(self.encoder.epochs):\n",
    "            # Forward pass: Encode input into latent space\n",
    "            encoded = self.encoder.predict(X)  # Shape: (batch_size, latent_size)\n",
    "\n",
    "            # Forward pass: Decode latent space back to input space\n",
    "            decoded = self.decoder.predict(encoded)  # Shape: (batch_size, input_size)\n",
    "\n",
    "            # Ensure decoded shape matches input shape\n",
    "            assert decoded.shape == X.shape, f\"Shape mismatch: X.shape={X.shape}, decoded.shape={decoded.shape}\"\n",
    "\n",
    "            # Compute the loss (MSE)\n",
    "            loss = np.mean((X - decoded) ** 2)\n",
    "            print(f'Epoch {epoch + 1}, Loss: {loss}')\n",
    "\n",
    "            # Train both encoder and decoder\n",
    "            self.encoder.fit(X, encoded)  # Train encoder\n",
    "            self.decoder.fit(encoded, X)  # Train decoder\n",
    "\n",
    "    def get_latent(self, X):\n",
    "        \"\"\"\n",
    "        Get the latent (compressed) representation.\n",
    "        \"\"\"\n",
    "        X = np.array(X, dtype=float)\n",
    "        return self.encoder.predict(X)\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        \"\"\"\n",
    "        Reconstruct the input from the latent space.\n",
    "        \"\"\"\n",
    "        X = np.array(X, dtype=float)\n",
    "        encoded = self.encoder.predict(X)\n",
    "        return self.decoder.predict(encoded)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "input_size = X_train.shape[1] \n",
    "hidden_layers = []  \n",
    "latent_size = 11  \n",
    "\n",
    "# Initialize the AutoEncoder\n",
    "autoencoder = AutoEncoder(\n",
    "    input_size=input_size,\n",
    "    hidden_layers=hidden_layers,\n",
    "    latent_size=latent_size,\n",
    "    activation='sigmoid',\n",
    "    optimizer='mini_batch',\n",
    "    learning_rate=0.01,\n",
    "    batch_size=32,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Train the AutoEncoder\n",
    "autoencoder.fit(X_train)\n",
    "latent_train = autoencoder.get_latent(X_train)\n",
    "\n",
    "latent_test = autoencoder.get_latent(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.12728501927329697\n",
      "Accuracy: 0.13666666666666666\n",
      "Precision: 0.12858004746655868\n",
      "Recall: 0.13543195595414487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(latent_train)\n",
    "# X_test = scaler.fit_transform(latent_test)\n",
    "\n",
    "# Apply KNN on the reduced (latent) data\n",
    "knn = KNeighborsClassifier(n_neighbors=21)  # Choose the number of neighbors\n",
    "knn.fit(latent_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = knn.predict(latent_test)\n",
    "\n",
    "# Calculate metrics\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score: 0.15554806964131268\n",
    "Accuracy: 0.15728070175438597\n",
    "Precision: 0.18481438839813552\n",
    "Recall: 0.15530235139822637\n",
    "\n",
    "F1 Score: 0.14107610041627072\n",
    "Accuracy: 0.1430701754385965\n",
    "Precision: 0.1680051044628347\n",
    "Recall: 0.14123160530220016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 5.868777165061815\n",
      "Epoch 10, Loss: 5.762931788718743\n",
      "Epoch 20, Loss: 5.760627719520123\n",
      "Epoch 30, Loss: 5.757200884725359\n",
      "Epoch 40, Loss: 5.754648808829396\n",
      "Epoch 50, Loss: 5.754189979032328\n",
      "Epoch 60, Loss: 5.753526066564644\n",
      "Epoch 70, Loss: 5.752340388685744\n",
      "Epoch 80, Loss: 5.754137128429252\n",
      "Epoch 90, Loss: 5.751849672913466\n",
      "MLP F1 Score: 0.00014687455536023278\n",
      "MLP Accuracy: 0.008421052631578947\n",
      "MLP Precision: 7.406378743693006e-05\n",
      "MLP Recall: 0.008681497558328812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, \n",
    "                 hidden_layers, \n",
    "                 learning_rate=0.01,\n",
    "                 activation='sigmoid',\n",
    "                 optimizer='sgd',\n",
    "                 batch_size=32,\n",
    "                 epochs=100,\n",
    "                 early_stopping_patience=10):\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation = activation\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.label_map = {}\n",
    "        self.reverse_label_map = {}\n",
    "\n",
    "    def _initialize_parameters(self, input_size, output_size):\n",
    "        layer_sizes = [input_size] + self.hidden_layers + [output_size]\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.weights.append(np.random.randn(layer_sizes[i-1], layer_sizes[i]) * np.sqrt(2. / layer_sizes[i-1]))\n",
    "            self.biases.append(np.zeros((1, layer_sizes[i])))\n",
    "\n",
    "    def _activation_function(self, x):\n",
    "        if self.activation == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-np.clip(x, -709, 709)))\n",
    "        elif self.activation == 'tanh':\n",
    "            return np.tanh(x)\n",
    "        elif self.activation == 'relu':\n",
    "            return np.maximum(0, x)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid activation function\")\n",
    "\n",
    "    def _activation_derivative(self, x):\n",
    "        if self.activation == 'sigmoid':\n",
    "            return x * (1 - x)\n",
    "        elif self.activation == 'tanh':\n",
    "            return 1 - np.power(x, 2)\n",
    "        elif self.activation == 'relu':\n",
    "            return np.where(x > 0, 1, 0)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid activation function\")\n",
    "\n",
    "    def _forward_propagation(self, X):\n",
    "        activations = [X]\n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
    "            a = self._activation_function(z)\n",
    "            activations.append(a)\n",
    "        return activations\n",
    "\n",
    "    def _backpropagation(self, X, y):\n",
    "        m = X.shape[0]\n",
    "        activations = self._forward_propagation(X)\n",
    "        \n",
    "        dW = [np.zeros_like(w) for w in self.weights]\n",
    "        db = [np.zeros_like(b) for b in self.biases]\n",
    "        \n",
    "        delta = activations[-1] - y\n",
    "        for l in range(len(self.weights) - 1, -1, -1):\n",
    "            dW[l] = np.dot(activations[l].T, delta) / m\n",
    "            db[l] = np.sum(delta, axis=0, keepdims=True) / m\n",
    "            if l > 0:\n",
    "                delta = np.dot(delta, self.weights[l].T) * self._activation_derivative(activations[l])\n",
    "        \n",
    "        return dW, db\n",
    "\n",
    "    def _update_parameters(self, dW, db):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * dW[i]\n",
    "            self.biases[i] -= self.learning_rate * db[i]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        unique_labels = np.unique(y)\n",
    "        n_classes = len(unique_labels)\n",
    "        self.label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        self.reverse_label_map = {idx: label for label, idx in self.label_map.items()}\n",
    "        \n",
    "        y_adjusted = np.array([self.label_map[label] for label in y])\n",
    "        \n",
    "        self._initialize_parameters(n_features, n_classes)\n",
    "        \n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            if self.optimizer == 'sgd':\n",
    "                indices = np.random.permutation(n_samples)\n",
    "                X_shuffled = X[indices]\n",
    "                y_shuffled = y_adjusted[indices]\n",
    "                for i in range(0, n_samples, self.batch_size):\n",
    "                    batch_X = X_shuffled[i:i+self.batch_size]\n",
    "                    batch_y = y_shuffled[i:i+self.batch_size]\n",
    "                    dW, db = self._backpropagation(batch_X, np.eye(n_classes)[batch_y])\n",
    "                    self._update_parameters(dW, db)\n",
    "\n",
    "            elif self.optimizer == 'batch':\n",
    "                dW, db = self._backpropagation(X, np.eye(n_classes)[y_adjusted])\n",
    "                self._update_parameters(dW, db)\n",
    "\n",
    "            elif self.optimizer == 'mini_batch':\n",
    "                for i in range(0, n_samples, self.batch_size):\n",
    "                    batch_X = X[i:i+self.batch_size]\n",
    "                    batch_y = y_adjusted[i:i+self.batch_size]\n",
    "                    dW, db = self._backpropagation(batch_X, np.eye(n_classes)[batch_y])\n",
    "                    self._update_parameters(dW, db)\n",
    "\n",
    "            loss = self._compute_cost(X, np.eye(n_classes)[y_adjusted])\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "            \n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= self.early_stopping_patience:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "\n",
    "    def predict(self, X):\n",
    "        activations = self._forward_propagation(X)\n",
    "        predicted_indices = np.argmax(activations[-1], axis=1)\n",
    "        return np.array([self.reverse_label_map[idx] for idx in predicted_indices])\n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        return np.mean(y_true == y_pred)\n",
    "\n",
    "    def _compute_cost(self, X, y):\n",
    "        activations = self._forward_propagation(X)\n",
    "        m = X.shape[0]\n",
    "        epsilon = 1e-15\n",
    "        cost = -np.sum(y * np.log(activations[-1] + epsilon) + (1 - y) * np.log(1 - activations[-1] + epsilon)) / m\n",
    "        return cost\n",
    "\n",
    "    def gradient_check(self, X, y, epsilon=1e-7):\n",
    "        y_adjusted = np.array([self.label_map[label] for label in y])\n",
    "        y_encoded = np.eye(len(self.label_map))[y_adjusted]\n",
    "        \n",
    "        dW, db = self._backpropagation(X, y_encoded)\n",
    "        \n",
    "        params = self.weights + self.biases\n",
    "        grads = dW + db\n",
    "        \n",
    "        num_grads = []\n",
    "        for param in params:\n",
    "            num_grad = np.zeros_like(param)\n",
    "            it = np.nditer(param, flags=['multi_index'], op_flags=['readwrite'])\n",
    "            while not it.finished:\n",
    "                idx = it.multi_index\n",
    "                old_value = param[idx]\n",
    "                \n",
    "                param[idx] = old_value + epsilon\n",
    "                cost_plus = self._compute_cost(X, y_encoded)\n",
    "                \n",
    "                param[idx] = old_value - epsilon\n",
    "                cost_minus = self._compute_cost(X, y_encoded)\n",
    "                \n",
    "                num_grad[idx] = (cost_plus - cost_minus) / (2 * epsilon)\n",
    "                \n",
    "                param[idx] = old_value\n",
    "                it.iternext()\n",
    "            \n",
    "            num_grads.append(num_grad)\n",
    "        \n",
    "        total_error = 0\n",
    "        for grad, num_grad in zip(grads, num_grads):\n",
    "            numerator = np.linalg.norm(grad - num_grad)\n",
    "            denominator = np.linalg.norm(grad) + np.linalg.norm(num_grad)\n",
    "            total_error += numerator / (denominator + 1e-7)\n",
    "        \n",
    "        average_error = total_error / len(params)\n",
    "        print(f\"Average relative error: {average_error}\")\n",
    "        \n",
    "        return average_error < 1e-7\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming you have X_train, y_train, X_val, and y_val prepared\n",
    "\n",
    "    # Create an instance of the MLP class with specified parameters.\n",
    "    mlp = MLP(hidden_layers=[64, 32],\n",
    "              learning_rate=0.001,\n",
    "              activation='relu',\n",
    "              optimizer='mini_batch',\n",
    "              batch_size=32,\n",
    "              epochs=100)\n",
    "\n",
    "    # Fit the model on training data.\n",
    "    mlp.fit(latent_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_mlp = mlp.predict(latent_test)\n",
    "\n",
    "    # Evaluate the MLP classifier\n",
    "    from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "    f1_mlp = f1_score(y_test.values, y_pred_mlp, average='macro')\n",
    "    accuracy_mlp = accuracy_score(y_test.values, y_pred_mlp)\n",
    "    precision_mlp = precision_score(y_test.values, y_pred_mlp, average='macro')\n",
    "    recall_mlp = recall_score(y_test.values, y_pred_mlp, average='macro')\n",
    "\n",
    "    print(f'MLP F1 Score: {f1_mlp}')\n",
    "    print(f'MLP Accuracy: {accuracy_mlp}')\n",
    "    print(f'MLP Precision: {precision_mlp}')\n",
    "    print(f'MLP Recall: {recall_mlp}')\n",
    "\n",
    "    # Perform gradient checking on a sample of validation data.\n",
    "    # is_gradient_correct = mlp.gradient_check(X_val[:10], y_val[:10])\n",
    "    # print(f\"Gradient check passed: {is_gradient_correct}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP F1 Score: 0.00015406745713950122\n",
      "MLP Accuracy: 0.008859649122807017\n",
      "MLP Precision: 7.771622037550016e-05\n",
      "MLP Recall: 0.008771929824561403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# # Define the MLP model\n",
    "# mlp=MLP(hidden_layers=[64, 32],\n",
    "#             learning_rate=0.03026,\n",
    "#             activation='relu',\n",
    "#             optimizer='sgd',batch_size=64,\n",
    "#             epochs=50)\n",
    "\n",
    "# # Train the MLP on the original dataset (X_train, y_train)\n",
    "# mlp.fit(latent_train, y_train)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred_mlp = mlp.predict(latent_test)\n",
    "\n",
    "# Evaluate the MLP classifier\n",
    "f1_mlp = f1_score(y_test, y_pred_mlp, average='macro')\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "precision_mlp = precision_score(y_test, y_pred_mlp, average='macro')\n",
    "recall_mlp = recall_score(y_test, y_pred_mlp, average='macro')\n",
    "\n",
    "print(f'MLP F1 Score: {f1_mlp}')\n",
    "print(f'MLP Accuracy: {accuracy_mlp}')\n",
    "print(f'MLP Precision: {precision_mlp}')\n",
    "print(f'MLP Recall: {recall_mlp}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hip-hop' 'hip-hop' 'hip-hop' ... 'hip-hop' 'brazil' 'hip-hop']\n",
      "23342     deep-house\n",
      "56496      indie-pop\n",
      "30524            edm\n",
      "92703     rockabilly\n",
      "96875          samba\n",
      "             ...    \n",
      "47535      hard-rock\n",
      "55640         indian\n",
      "45354         guitar\n",
      "63715         j-rock\n",
      "104083       spanish\n",
      "Name: track_genre, Length: 11400, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_mlp)\n",
    "print(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
